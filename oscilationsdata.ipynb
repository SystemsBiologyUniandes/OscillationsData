{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import bayes_mvs as bayesest\n",
    "import os #Lib for get the operative system sintaxis\n",
    "from sklearn import linear_model#Machine learning package for a smart plot fit\n",
    "from scipy import stats\n",
    "from decimal import Decimal\n",
    "import math\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexes(y):#peak detection algorithm\n",
    "    dy = np.diff(y)\n",
    "    #plt.plot(ady)\n",
    "    ind = []\n",
    "    for i in range(len(dy)-1):\n",
    "        if len(ind) > 0:\n",
    "            if abs(dy[i-1])<0.25*y[i] and dy[i]<-0.3*y[i] and abs(dy[i+1])<0.25*y[i]:\n",
    "                ind.append(i)\n",
    "        elif len(ind) == 0:\n",
    "            if  dy[i]<-0.3*y[i]:\n",
    "                ind.append(i)\n",
    "    return ind  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lane=1\n",
    "timebetframes=15/60\n",
    "medium='m3'\n",
    "peakdist=2\n",
    "fitthresh=0.8 #threshold in the fit score to consider the cell cicle\n",
    "pixelsize=0.11 #pixelsize (mum/px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./RawDataAdder.csv\")\n",
    "replica=data['Replica'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "data=pd.read_csv(\"./RawDataAdder.csv\")\n",
    "replica=data['Replica'].unique()\n",
    "\n",
    "    \n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "#data=dataraw[dataraw.lane_num==lane]\n",
    "\n",
    "DSMdata=[]#np.array([[\"Sb\",\"Sd\",\"gr\",\"timediv\",\"score\",\"Replica\"]])\n",
    "CRMdata=[]#np.array([[\"Mother\",\"time\",\"SizeFit\",\"Size\",\"gr\",\"score\",\"Replica\"]])\n",
    "CRMdatasyn=[]\n",
    "#td=[]\n",
    "#goodsz=[]\n",
    "#grsimple=[]\n",
    "#gooddata=[]\n",
    "filtdata=[]\n",
    "repinx=1\n",
    "for rep in replica:\n",
    "    df=data[data.Replica==rep]\n",
    "    moms=df['mom'].unique()\n",
    "    grs=[]\n",
    "    df=df.reset_index()\n",
    "    tbf=(df.loc[1].time-df.loc[0].time)*15/60\n",
    "    for k in range(len(moms)):\n",
    "        tempCRM=[]\n",
    "        tempCRMsyn=[]\n",
    "        tempv=[]\n",
    "        dataM=df[df.mom==moms[k]]\n",
    "        datat=dataM.sort_values(by=\"time\")\n",
    "        ln = np.array(datat.length)\n",
    "        \n",
    "        time = np.array(datat.time*15/60)\n",
    "        \n",
    "        peaksval=[]  \n",
    "        fitl=[]\n",
    "        fitt=[]\n",
    "        peaks = indexes(ln)\n",
    "        avscore=[]\n",
    "        if (len(peaks)!=0):\n",
    "            coor=[]\n",
    "            for i in range(len(peaks)):        \n",
    "                if(i>0):\n",
    "                    d=float(time[peaks[i]]-time[peaks[i-1]])#division time\n",
    "                    tt=peaks[i-1]+1#initial time for ransac estimation\n",
    "                    tt2=peaks[i-1]-peaks[0]+1\n",
    "                else:\n",
    "                    d=0\n",
    "                    tt=0\n",
    "                peaksval.append([time[peaks[i]],ln[peaks[i]]]) \n",
    "                dt=[]#array of log(len)\n",
    "                tm=[]\n",
    "                results=[]\n",
    "                temp=0\n",
    "                while(tt<=peaks[i]):\n",
    "                    dt.append(np.log(ln[tt]))\n",
    "                    tm.append(temp)\n",
    "                    temp=temp+tbf\n",
    "                    tt=tt+1\n",
    "                if(len(dt)>1):#guarantees there is enought data\n",
    "                    tm = np.array(tm).reshape((len(tm), 1))#converting a row into a column\n",
    "                    model_ransac = linear_model.RANSACRegressor(linear_model.LinearRegression(),residual_threshold=0.05)\n",
    "                    model_ransac.fit(tm,dt)#smart fit\n",
    "                    a=model_ransac.estimator_.coef_#growth rate\n",
    "                    l0=np.exp(model_ransac.estimator_.intercept_)\n",
    "                    avscore.append(model_ransac.score(tm, dt))\n",
    "                    if(i>0):\n",
    "                        tt=peaks[i-1]+1#temporaltime\n",
    "                        tt2=peaks[i-1]-peaks[0]+1\n",
    "                        score=model_ransac.score(tm,dt)\n",
    "                        while(tt<=peaks[i]):\n",
    "                            tempCRM.append([moms[k],time[tt],l0*np.exp((-time[peaks[i-1]+1]+time[tt])*a[0]),ln[tt],a[0],score,repinx]) \n",
    "                            tempCRMsyn.append([moms[k],time[tt2],l0*np.exp((-time[peaks[i-1]+1]+time[tt])*a[0]),ln[tt],a[0],score,repinx]) \n",
    "                            tt+=1\n",
    "                            tt2+=1\n",
    "                        if(score>0.9):                        \n",
    "                            tempvf=l0*np.exp((-time[peaks[i-1]+1]+time[peaks[i]]+(tbf/2))*a[0])\n",
    "                            tempv0=l0*np.exp(-tbf*a[0]/2)\n",
    "                            if tempvf>tempv0:                            \n",
    "                                avt=(time[peaks[i-1]]+time[peaks[i]])/2\n",
    "                                timediv=-time[peaks[i-1]]+time[peaks[i]]\n",
    "                                tempv.append([tempv0,tempvf,tempvf-tempv0,a[0],avt,timediv,score,repinx])\n",
    "                                tt=peaks[i-1]+1#temporaltime\n",
    "                                if(model_ransac.score(tm,dt)>fitthresh):\n",
    "                                    coor.append([time[peaks[i]],pixelsize*ln[peaks[i]],model_ransac.score(tm,dt)])\n",
    "                        tt=peaks[i-1]+1#temporaltime\n",
    "                        score=model_ransac.score(tm,dt)\n",
    "                            \n",
    "                                \n",
    "                    else:\n",
    "                        tt=0\n",
    "                        score=model_ransac.score(tm,dt)\n",
    "                        while(tt<=peaks[i]):\n",
    "                            tempCRM.append([moms[k],time[tt],l0*np.exp((-time[0]+time[tt])*a[0]),ln[tt],a[0],score,repinx]) \n",
    "                            tt=tt+1 \n",
    "            peaksval=np.array(peaksval)\n",
    "        if len(tempv)>6:\n",
    "            fitl=[]\n",
    "            fitt=[]\n",
    "            for gg in tempCRM:     \n",
    "                if len(CRMdata)==0:\n",
    "                    CRMdata=[gg]\n",
    "                else:\n",
    "                    CRMdata=np.concatenate((CRMdata,[gg]),axis=0)\n",
    "                \n",
    "                fitl.append(gg[2])\n",
    "                fitt.append(gg[1])\n",
    "            for gg in tempCRMsyn:     \n",
    "                if len(CRMdatasyn)==0:\n",
    "                    CRMdatasyn=[gg]\n",
    "                else:\n",
    "                    CRMdatasyn=np.concatenate((CRMdatasyn,[gg]),axis=0)\n",
    "            for pp in tempv:\n",
    "                if len(DSMdata)==0:\n",
    "                    DSMdata=[pp]\n",
    "                else:\n",
    "                    DSMdata=np.concatenate((DSMdata,[pp]),axis=0)\n",
    "    print(repinx)\n",
    "    repinx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(DSMdata,columns=[\"Sb\",\"Sd\",\"Added\",\"gr\",\"timediv\",\"timecycle\",\"score\",\"Replica\"])\n",
    "dataf=pd.DataFrame(columns=[\"Sb\",\"Sd\",\"Added\",\"gr\",\"timediv\",\"timecycle\",\"score\",\"Replica\"])\n",
    "Rep=df.Replica.unique()\n",
    "for r in Rep:\n",
    "    df2=df[df.Replica==r]\n",
    "    sz=np.mean(df2.Sb)\n",
    "    dftemp=pd.DataFrame(columns=[\"Sb\",\"Sd\",\"Added\",\"gr\",\"timediv\",\"timecycle\",\"score\",\"Replica\"])\n",
    "    dftemp['Sb']=df2.Sb/sz\n",
    "    dftemp['Sd']=df2.Sd/sz\n",
    "    dftemp['Added']=df2.Sb/sz\n",
    "    dftemp['gr']=df2.gr\n",
    "    dftemp['timediv']=df2.timediv\n",
    "    dftemp['timecycle']=df2.timecycle*np.mean(df2.gr)/np.log(2)\n",
    "    dftemp['score']=df2.score\n",
    "    dftemp['Replica']=df2.Replica\n",
    "    dataf=pd.concat([dataf,dftemp])\n",
    "    \n",
    "df=dataf\n",
    "df=df[np.abs(scipy.stats.zscore(df.Sd))<3.5]\n",
    "df=df[np.abs(scipy.stats.zscore(df.Sb))<3.5]\n",
    "df=df[np.abs(scipy.stats.zscore(df.Added))<3.5]\n",
    "df=df[np.abs(scipy.stats.zscore(df.gr))<3.5]\n",
    "df=df[np.abs(scipy.stats.zscore(df.timecycle))<4]\n",
    "df=df[df.score>0.8]\n",
    "\n",
    "\n",
    "df.to_csv(\"./DSMdataAdder.csv\",index=False)\n",
    "\n",
    "#df.to_csv(\"./DSMdataAdder.csv\",index=False)\n",
    "df=pd.DataFrame(CRMdata,columns=[\"Mother\",\"time\",\"SizeFit\",\"Size\",\"gr\",\"score\",\"Replica\"])\n",
    "szs=[18,19.2]\n",
    "dataf=pd.DataFrame(columns=[\"Mother\",\"time\",\"SizeFit\",\"Size\",\"gr\",\"score\",\"Replica\"])\n",
    "Rep=df.Replica.unique()\n",
    "i=0\n",
    "for r in Rep:\n",
    "    df2=df[df.Replica==r]\n",
    "    sz=szs[i]\n",
    "    dftemp=df2\n",
    "    dftemp['SizeFit']=dftemp.SizeFit/sz\n",
    "    dftemp['Size']=dftemp.Size/sz\n",
    "    i+=1\n",
    "    dataf=pd.concat([dataf,dftemp])\n",
    "df=dataf\n",
    "df.to_csv(\"./CRMdataAdder.csv\",index=False)\n",
    "df=pd.DataFrame(CRMdatasyn,columns=[\"Mother\",\"time\",\"SizeFit\",\"Size\",\"gr\",\"score\",\"Replica\"])\n",
    "szs=[18,19.2]\n",
    "dataf=pd.DataFrame(columns=[\"Mother\",\"time\",\"SizeFit\",\"Size\",\"gr\",\"score\",\"Replica\"])\n",
    "Rep=df.Replica.unique()\n",
    "i=0\n",
    "for r in Rep:\n",
    "    df2=df[df.Replica==r]\n",
    "    sz=szs[i]\n",
    "    dftemp=df2\n",
    "    dftemp['SizeFit']=dftemp.SizeFit/sz\n",
    "    dftemp['Size']=dftemp.Size/sz\n",
    "    i+=1\n",
    "    dataf=pd.concat([dataf,dftemp])\n",
    "df=dataf\n",
    "df.to_csv(\"./CRMdataAddersyn.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv(\"./CRMdataAdder.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv(\"./DSMdataAdder.csv\")\n",
    "for r in [1,2,3]:\n",
    "    df=data1[data1.Replica==r]\n",
    "    plt.scatter(df.Sb,df.Sd-df.Sb,s=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./CRMdataAddersyn.csv\")\n",
    "plt.plot(data[data.Mother==0].time,data[data.Mother==0].SizeFit)\n",
    "plt.scatter(data[data.Mother==0].time,data[data.Mother==0].Size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./CRMdataAddersyn.csv\")\n",
    "i=0\n",
    "for r in [1,3]:\n",
    "    df=data[data.Replica==r]\n",
    "    tarray=np.sort(df.time.unique())\n",
    "    meansz=[]\n",
    "    errorsz=[]\n",
    "    meancv2sz=[]\n",
    "    errorcv2sz=[]\n",
    "    for t in tarray:\n",
    "        dft=df[df.time==t]\n",
    "        if (len(df)>1):\n",
    "#        timecorrect.append(t)\n",
    "            mean_cntr, var_cntr, std_cntr = bayesest(dft.Size,alpha=0.95)\n",
    "            meansz.append(mean_cntr[0])\n",
    "            errorsz.append(mean_cntr[1][1]-mean_cntr[0])\n",
    "            meancv2sz.append(var_cntr[0]/mean_cntr[0]**2)\n",
    "            errv=(var_cntr[1][1]-var_cntr[0])/mean_cntr[0]**2+2*(mean_cntr[1][1]-mean_cntr[0])*var_cntr[0]/mean_cntr[0]**3\n",
    "            errorcv2sz.append(errv)\n",
    "            #errorcv2gr.append((std_cntr[1][1]-std_cntr[0])/mean_cntr[0]+(mean_cntr[1][1]-mean_cntr[0])*std_cntr[0]/(mean_cntr[0])**2)\n",
    "    plt.plot(tarray,meansz,lw=3)\n",
    "    plt.fill_between(tarray, np.array(meansz)+np.array(errorsz), np.array(meansz)-np.array(errorsz),alpha=1, edgecolor='#4db8ff', facecolor='#4db8ff',\n",
    "    linewidth=0)\n",
    "    i+=1\n",
    "plt.xlim(0,6)\n",
    "plt.ylim(1,1.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./CRMdataAdder.csv\")\n",
    "\n",
    "for r in [1,2,3]:\n",
    "    df=data[data.Replica==r]\n",
    "    tarray=np.sort(df.time.unique())\n",
    "    meansz=[]\n",
    "    errorsz=[]\n",
    "    meancv2sz=[]\n",
    "    errorcv2sz=[]\n",
    "    for t in tarray:\n",
    "        dft=df[df.time==t]\n",
    "        if (len(df)>1):\n",
    "#        timecorrect.append(t)\n",
    "            mean_cntr, var_cntr, std_cntr = bayesest(dft.Size,alpha=0.95)\n",
    "            meansz.append(mean_cntr[0])\n",
    "            errorsz.append(mean_cntr[1][1]-mean_cntr[0])\n",
    "            meancv2sz.append(var_cntr[0]/mean_cntr[0]**2)\n",
    "            errv=(var_cntr[1][1]-var_cntr[0])/mean_cntr[0]**2+2*(mean_cntr[1][1]-mean_cntr[0])*var_cntr[0]/mean_cntr[0]**3\n",
    "            errorcv2sz.append(errv)\n",
    "            #errorcv2gr.append((std_cntr[1][1]-std_cntr[0])/mean_cntr[0]+(mean_cntr[1][1]-mean_cntr[0])*std_cntr[0]/(mean_cntr[0])**2)\n",
    "    plt.plot(tarray,meansz,lw=3)\n",
    "    plt.fill_between(tarray, np.array(meansz)+np.array(errorsz), np.array(meansz)-np.array(errorsz),alpha=1, edgecolor='#4db8ff', facecolor='#4db8ff',\n",
    "    linewidth=0)\n",
    "#plt.ylim([0,0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
    "data2=pd.read_csv(\"./DSMdataAdder.csv\")\n",
    "ax[0].scatter(data2.Sb/np.mean(data2.Sb),(data2.Sd-data2.Sb)/np.mean(data2.Sb),s=2)\n",
    "\n",
    "quantnumber=5\n",
    "pvadd2=data2\n",
    "CV2d=[]\n",
    "delt=[]\n",
    "sb=[]\n",
    "    \n",
    "errcv2d=[]\n",
    "errdelt=[]\n",
    "errsb=[]\n",
    "for i in range(quantnumber):\n",
    "    lperv0=np.percentile(pvadd2.Sb,i*100/quantnumber)\n",
    "    hperv0=np.percentile(pvadd2.Sb,(i+1)*100/quantnumber)\n",
    "    quanta1=pvadd2[pvadd2.Sb>lperv0]\n",
    "    quanta2=quanta1[quanta1.Sb<hperv0]     \n",
    "    mean_cntr, var_cntr, std_cntr = bayesest((quanta2.Sd-quanta2.Sb)/np.mean(pvadd2.Sd-pvadd2.Sb),alpha=0.95)\n",
    "    meanv0_cntr, varv0_cntr, stdv0_cntr = bayesest(quanta2.Sb/np.mean(pvadd2.Sb),alpha=0.95)\n",
    "    CV2d.append(var_cntr[0]/mean_cntr[0]**2)\n",
    "    delt.append(mean_cntr[0])\n",
    "    sb.append(meanv0_cntr[0])\n",
    "    errv=(var_cntr[1][1]-var_cntr[0])/mean_cntr[0]**2+2*(mean_cntr[1][1]-mean_cntr[0])*var_cntr[0]/mean_cntr[0]**3\n",
    "    errcv2d.append(errv)\n",
    "    errdelt.append(mean_cntr[1][1]-mean_cntr[0])\n",
    "    errsb.append(meanv0_cntr[1][1]-meanv0_cntr[0])\n",
    "ax[0].errorbar(np.array(sb),np.array(delt),xerr=errsb,yerr=errdelt, fmt='o',mec='k',capsize=5,markersize='8',elinewidth=3,c='#0075BD')\n",
    "ax[1].errorbar(np.array(sb),CV2d,xerr=errsb,yerr=errcv2d, fmt='o',mec='k',capsize=5,markersize='8',elinewidth=3,c='#0075BD')\n",
    "ax[1].set_ylim([0,0.3])\n",
    "\n",
    "\n",
    "#lamb=1.5\n",
    "#nsteps=8\n",
    "#s0=(1/nsteps)**(1/lamb)\n",
    "#xx = np.arange(0,3,0.01)\n",
    "#def rel(x):\n",
    "#    return lamb**(1/lamb)*np.exp((x)**lamb/lamb)*scipy.special.gamma(1+1/lamb)*scipy.special.gammaincc(1+1/lamb,(x)**lamb/lamb)-2*x\n",
    "#s0r=scipy.optimize.bisect(rel,0,100)\n",
    "#avg=s0*np.exp((xx/s0)**lamb/lamb)*lamb**(1/lamb)*scipy.special.gamma(1+1/lamb)*scipy.special.gammaincc(1+1/lamb, (xx/s0)**lamb/lamb)\n",
    "#avg2=s0*s0*lamb**(2/lamb)*np.exp((xx/s0)**lamb/lamb)*scipy.special.gamma(1+2/lamb)*scipy.special.gammaincc(1+2/lamb, (xx/s0)**lamb/lamb)\n",
    "\n",
    "#ax[0].plot(sbarray/1.55,(np.array(sizedivarr05)-np.array(sbarray))/1.55,lw=2,label='$\\gamma_p=\\mu$',c='#E00000',linestyle='dotted')\n",
    "#ax[1].plot(sbarray/1.55,np.array(CV2arr05),lw=2,c='#E00000',linestyle='dotted')\n",
    "#ax[0].plot(xx/(s0*s0r),((avg-xx)/s0)/(s0r),lw=3,label='$\\lambda=%.1f$' %lamb,c='#2DB102',linestyle='dashed')    \n",
    "#ax[1].plot(xx/(s0*s0r),(avg2-avg**2)/(nsteps*(avg-xx)**2),lw=3,c='#2DB102',linestyle='dashed')\n",
    "#ax[1].plot(sbarray2/1.25,np.array(CV2arr01a),lw=2,c='k',label='$s_0=1,H=2.5,M=9$')\n",
    "#ax[0].plot(sbarray2/1.25,(np.array(sizedivarr01a)-np.array(sbarray2))/1.25,lw=3,c='k')\n",
    "#ax[1].legend(fontsize=15)\n",
    "\n",
    "ax[0].set_xlim(0.5,1.5)\n",
    "ax[1].set_xlim(0.5,1.5)\n",
    "for i in [0,1]:\n",
    "    ax[i].grid()\n",
    "    ax[i].tick_params(axis='x', labelsize=15)\n",
    "    ax[i].tick_params(axis='y', labelsize=15)\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax[i].spines[axis].set_linewidth(2)\n",
    "        ax[i].tick_params(axis='both', width=2,length=6)\n",
    "        #ax[i].legend(fontsize=15)\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "ax[0].set_ylabel(r'$\\Delta/\\overline{s_b}$',size=20)\n",
    "ax[1].set_ylabel(r'$C^2_v(\\Delta)$',size=20)\n",
    "ax[1].set_ylim(0.05,0.14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "data=pd.read_csv(\"./CRMdataAdder.csv\")\n",
    "data=data[data.score>0.9]\n",
    "for rep in [1,2,3]:\n",
    "    df=data[data.Replica==rep]\n",
    "    tarray=np.sort(df.time.unique())\n",
    "    meangr=[]\n",
    "    errorgr=[]\n",
    "    meancv2gr=[]\n",
    "    errorcv2gr=[]\n",
    "    for t in tarray:\n",
    "        dft=df[df.time==t]\n",
    "        if (len(df)>1):\n",
    "#        timecorrect.append(t)\n",
    "            mean_cntr, var_cntr, std_cntr = bayesest(dft.gr,alpha=0.95)\n",
    "            meangr.append(mean_cntr[0])\n",
    "            errorgr.append(mean_cntr[1][1]-mean_cntr[0])\n",
    "            meancv2gr.append(var_cntr[0]/mean_cntr[0]**2)\n",
    "            errv=(var_cntr[1][1]-var_cntr[0])/mean_cntr[0]**2+2*(mean_cntr[1][1]-mean_cntr[0])*var_cntr[0]/mean_cntr[0]**3\n",
    "            errorcv2gr.append(errv)\n",
    "            #errorcv2gr.append((std_cntr[1][1]-std_cntr[0])/mean_cntr[0]+(mean_cntr[1][1]-mean_cntr[0])*std_cntr[0]/(mean_cntr[0])**2)\n",
    "    plt.plot(tarray,meangr,lw=3)\n",
    "    plt.fill_between(tarray, np.array(meangr)+np.array(errorgr), np.array(meangr)-np.array(errorgr),alpha=1, edgecolor='#4db8ff', facecolor='#4db8ff',\n",
    "    linewidth=0)\n",
    "plt.ylim([0,0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_size = 1 # femto liter\n",
    "doubling_time = 18 #min\n",
    "tmax = 180 #min\n",
    "sample_time = 2 #min\n",
    "div_steps = 25\n",
    "ncells = 5000 \n",
    "gr = np.log(2)/doubling_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyEcoLib.simulator import Simulator\n",
    "\n",
    "CV2sz = 0.02\n",
    "CV2div = 0.01\n",
    "CV2gr = 0.015\n",
    "v0 = mean_size*np.random.gamma(shape=1/CV2sz,scale=CV2sz,size=ncells)\n",
    "sim = Simulator(ncells=ncells, gr = gr, sb=mean_size, steps = div_steps, CV2div = CV2div, CV2gr = CV2gr,V0array=v0)\n",
    "sim.szdyn(tmax = tmax, sample_time= 0.1*doubling_time, nameCRM = \"./dataCRM3.csv\")\n",
    "#print('It took', np.int(time.time()-start), 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./dataCRM3.csv\")\n",
    "taumax=55\n",
    "tauarr3=range(taumax)\n",
    "tarr=data.time.tolist()\n",
    "corarr3=[]\n",
    "for tau in tauarr3:\n",
    "    xx=[]\n",
    "    yy=[]\n",
    "    for i in range(20):\n",
    "        df=data[data.time==tarr[i]]\n",
    "        del df['time']\n",
    "        df2=data[data.time==tarr[i+tau]]\n",
    "        del df2['time']\n",
    "        #print(df.iloc[0].tolist())\n",
    "        A=df.iloc[0].tolist()\n",
    "        B=df2.iloc[0].tolist()\n",
    "        for m in range(len(A)):\n",
    "            xx.append(A[m])\n",
    "        for m in range(len(A)):\n",
    "            yy.append(B[m])\n",
    "        #xx.append()\n",
    "        #yy.append(df2.tolist())\n",
    "    corarr3.append(np.corrcoef(xx,yy)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./CRMdataAddersyn.csv\")\n",
    "data=data[data.Replica==1]\n",
    "taumax=25\n",
    "tauarr2=range(taumax)\n",
    "tarr=data.time.tolist()\n",
    "corarr2=[]\n",
    "for tau in tauarr2:\n",
    "    print(tau)\n",
    "    xx=[]\n",
    "    yy=[]\n",
    "    for i in np.arange(0,20,2):\n",
    "        \n",
    "        df=data[data.time==tarr[i]]\n",
    "        datamom1=df.Mother.unique()\n",
    "        del df['time']\n",
    "        df2=data[data.time==tarr[i+tau]]\n",
    "        datamom2=df2.Mother.unique()\n",
    "        allmom=[]\n",
    "        A=[]\n",
    "        B=[]\n",
    "        for m in datamom1:\n",
    "            if m in datamom2:\n",
    "                A.append(df[df.Mother==m].Size.tolist()[0])\n",
    "                B.append(df2[df2.Mother==m].Size.tolist()[0])\n",
    "        del df2['time']\n",
    "\n",
    "        \n",
    "        for m in range(len(A)):\n",
    "            xx.append(A[m])\n",
    "        for m in range(len(A)):\n",
    "            yy.append(B[m])\n",
    "        #xx.append()\n",
    "        #yy.append(df2.tolist())\n",
    "    corarr2.append(np.corrcoef(xx,yy)[0][1])\n",
    "#inspace(0,3.15,len(corarr2)),corarr2,label=\"Experiment\",c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corarr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(tauarr3)/10,corarr3)\n",
    "plt.scatter(np.array(tauarr2)*0.25*0.95,corarr2)\n",
    "plt.xlim(0,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv(\"./CRMdataAddersyn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./CRMdataAddersyn.csv\")\n",
    "i=0\n",
    "for r in [1]:\n",
    "    df=data\n",
    "    tarray3=np.sort(df.time.unique())\n",
    "    meansz3=[]\n",
    "    errorsz3=[]\n",
    "    meancv2sz3=[]\n",
    "    errorcv2sz3=[]\n",
    "    for t in tarray3:\n",
    "        dft=df[df.time==t]\n",
    "        if (len(df)>1):\n",
    "#        timecorrect.append(t)\n",
    "            mean_cntr, var_cntr, std_cntr = bayesest(dft.Size,alpha=0.95)\n",
    "            meansz3.append(mean_cntr[0])\n",
    "            errorsz3.append(mean_cntr[1][1]-mean_cntr[0])\n",
    "            meancv2sz3.append(var_cntr[0]/mean_cntr[0]**2)\n",
    "            errv=(var_cntr[1][1]-var_cntr[0])/mean_cntr[0]**2+2*(mean_cntr[1][1]-mean_cntr[0])*var_cntr[0]/mean_cntr[0]**3\n",
    "            errorcv2sz3.append(errv)\n",
    "            #errorcv2gr.append((std_cntr[1][1]-std_cntr[0])/mean_cntr[0]+(mean_cntr[1][1]-mean_cntr[0])*std_cntr[0]/(mean_cntr[0])**2)\n",
    "    plt.plot(tarray3,meansz3,lw=3)\n",
    "    plt.fill_between(tarray3, np.array(meansz3)+np.array(errorsz3), np.array(meansz3)-np.array(errorsz3),alpha=1, edgecolor='#4db8ff', facecolor='#4db8ff',\n",
    "    linewidth=0)\n",
    "    i+=1\n",
    "plt.xlim(0,6)\n",
    "plt.ylim(1,1.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv(\"./dataCRM3.csv\")\n",
    "timearray3=data1.time.unique()\n",
    "\n",
    "mnszarray3=[]\n",
    "cvszarray3=[]\n",
    "errcv2sz3=[]\n",
    "errmnsz3=[]\n",
    "df=data1\n",
    "del df['time']\n",
    "for m in range(len(df)):\n",
    "    szs=df.loc[m, :].values.tolist()\n",
    "    mean_cntr, var_cntr, std_cntr = bayesest(szs,alpha=0.95)\n",
    "    mnszarray3.append(np.mean(szs))\n",
    "    errmnsz3.append(mean_cntr[1][1]-mean_cntr[0])\n",
    "    cvszarray3.append(np.var(szs)/np.mean(szs)**2)\n",
    "    errv=(var_cntr[1][1]-var_cntr[0])/mean_cntr[0]**2+2*(mean_cntr[1][1]-mean_cntr[0])*var_cntr[0]/mean_cntr[0]**3\n",
    "    errcv2sz3.append(errv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./CRMdataAddersyn.csv\")\n",
    "df=data\n",
    "tarray=np.sort(df.time.unique())\n",
    "meansz=[]\n",
    "errorsz=[]\n",
    "meancv2sz=[]\n",
    "errorcv2sz=[]\n",
    "for t in tarray:\n",
    "    dft=df[df.time==t]\n",
    "    print(len(dft))\n",
    "    if (len(df)>1):\n",
    "#        timecorrect.append(t)\n",
    "        mean_cntr, var_cntr, std_cntr = bayesest(dft.Size,alpha=0.95)\n",
    "        meansz.append(mean_cntr[0])\n",
    "        errorsz.append(mean_cntr[1][1]-mean_cntr[0])\n",
    "        meancv2sz.append(var_cntr[0]/mean_cntr[0]**2)\n",
    "        errv=(var_cntr[1][1]-var_cntr[0])/mean_cntr[0]**2+2*(mean_cntr[1][1]-mean_cntr[0])*var_cntr[0]/mean_cntr[0]**3\n",
    "        errorcv2sz.append(errv)\n",
    "            #errorcv2gr.append((std_cntr[1][1]-std_cntr[0])/mean_cntr[0]+(mean_cntr[1][1]-mean_cntr[0])*std_cntr[0]/(mean_cntr[0])**2)\n",
    "plt.errorbar((np.array(tarray)-0.2),(np.array(meansz)+0.05),yerr=errorcv2sz,\n",
    "                               color='#008658',capsize=3,fmt='o',markersize='3',elinewidth=2)\n",
    "plt.fill_between(timearray3/18, np.array(mnszarray3)+np.array(errmnsz3), np.array(mnszarray3)-np.array(errmnsz3),alpha=1, edgecolor='#4db8ff', facecolor='#4db8ff',\n",
    "    linewidth=0)    #        plt.scatter(tarray,meansz,lw=3)\n",
    "    #plt.fill_between(tarray, np.array(meansz)+np.array(errorsz), np.array(meansz)-np.array(errorsz),alpha=1, edgecolor='#4db8ff', facecolor='#4db8ff',\n",
    "    #linewidth=0)\n",
    "plt.xlim(0,5)\n",
    "plt.ylim(0.9,1.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./CRMdataAddersyn.csv\")\n",
    "df=data\n",
    "tarray=np.sort(df.time.unique())\n",
    "meansz=[]\n",
    "errorsz=[]\n",
    "meancv2sz=[]\n",
    "errorcv2sz=[]\n",
    "for t in tarray:\n",
    "    dft=df[df.time==t]\n",
    "    if (len(df)>1):\n",
    "#        timecorrect.append(t)\n",
    "        mean_cntr, var_cntr, std_cntr = bayesest(dft.Size,alpha=0.95)\n",
    "        meansz.append(mean_cntr[0])\n",
    "        errorsz.append(mean_cntr[1][1]-mean_cntr[0])\n",
    "        meancv2sz.append(var_cntr[0]/mean_cntr[0]**2)\n",
    "        errv=(var_cntr[1][1]-var_cntr[0])/mean_cntr[0]**2+2*(mean_cntr[1][1]-mean_cntr[0])*var_cntr[0]/mean_cntr[0]**3\n",
    "        errorcv2sz.append(errv)\n",
    "            #errorcv2gr.append((std_cntr[1][1]-std_cntr[0])/mean_cntr[0]+(mean_cntr[1][1]-mean_cntr[0])*std_cntr[0]/(mean_cntr[0])**2)\n",
    "plt.errorbar((np.array(tarray)-0.2)/1.03,meancv2sz,yerr=errorcv2sz,\n",
    "                               color='#008658',capsize=3,fmt='o',markersize='3',elinewidth=2)\n",
    "plt.fill_between(np.array(timearray3)/18,np.array(cvszarray3)-np.array(errcv2sz3),np.array(cvszarray3)\n",
    "                   +np.array(errcv2sz3),alpha=1, edgecolor='#4db8ff', facecolor='#4db8ff',linewidth=0)\n",
    "    #        plt.scatter(tarray,meansz,lw=3)\n",
    "    #plt.fill_between(tarray, np.array(meansz)+np.array(errorsz), np.array(meansz)-np.array(errorsz),alpha=1, edgecolor='#4db8ff', facecolor='#4db8ff',\n",
    "    #linewidth=0)\n",
    "plt.xlim(0,6)\n",
    "plt.ylim(0,0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:/Users/cesar/Documents/biofisica/sizerdata/DSMdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:/Users/cesar/Documents/biofisica/sizerdata/rawdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "data=pd.read_csv(\"C:/Users/cesar/Documents/biofisica/sizerdata/rawdata.csv\")\n",
    "replica=data['Replica'].unique()\n",
    "\n",
    "    \n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "#data=dataraw[dataraw.lane_num==lane]\n",
    "\n",
    "DSMdata=[]#np.array([[\"Sb\",\"Sd\",\"gr\",\"timediv\",\"score\",\"Replica\"]])\n",
    "CRMdata=[]#np.array([[\"Mother\",\"time\",\"SizeFit\",\"Size\",\"gr\",\"score\",\"Replica\"]])\n",
    "CRMdatasyn=[]\n",
    "#td=[]\n",
    "#goodsz=[]\n",
    "#grsimple=[]\n",
    "#gooddata=[]\n",
    "filtdata=[]\n",
    "repinx=1\n",
    "for rep in replica:\n",
    "    df=data[data.Replica==rep]\n",
    "    moms=df['mom'].unique()\n",
    "    grs=[]\n",
    "    df=df.reset_index()\n",
    "    tbf=(df.loc[1].time-df.loc[0].time)*15/60\n",
    "    for k in range(len(moms)):\n",
    "        tempCRM=[]\n",
    "        tempCRMsyn=[]\n",
    "        tempv=[]\n",
    "        dataM=df[df.mom==moms[k]]\n",
    "        datat=dataM.sort_values(by=\"time\")\n",
    "        ln = np.array(datat.length)\n",
    "        \n",
    "        time = np.array(datat.time*15/60)\n",
    "        \n",
    "        peaksval=[]  \n",
    "        fitl=[]\n",
    "        fitt=[]\n",
    "        peaks = indexes(ln)\n",
    "        avscore=[]\n",
    "        if (len(peaks)!=0):\n",
    "            coor=[]\n",
    "            for i in range(len(peaks)):        \n",
    "                if(i>0):\n",
    "                    d=float(time[peaks[i]]-time[peaks[i-1]])#division time\n",
    "                    tt=peaks[i-1]+1#initial time for ransac estimation\n",
    "                    tt2=peaks[i-1]-peaks[0]+1\n",
    "                else:\n",
    "                    d=0\n",
    "                    tt=0\n",
    "                peaksval.append([time[peaks[i]],ln[peaks[i]]]) \n",
    "                dt=[]#array of log(len)\n",
    "                tm=[]\n",
    "                results=[]\n",
    "                temp=0\n",
    "                while(tt<=peaks[i]):\n",
    "                    dt.append(np.log(ln[tt]))\n",
    "                    tm.append(temp)\n",
    "                    temp=temp+tbf\n",
    "                    tt=tt+1\n",
    "                if(len(dt)>1):#guarantees there is enought data\n",
    "                    tm = np.array(tm).reshape((len(tm), 1))#converting a row into a column\n",
    "                    model_ransac = linear_model.RANSACRegressor(linear_model.LinearRegression(),residual_threshold=0.05)\n",
    "                    model_ransac.fit(tm,dt)#smart fit\n",
    "                    a=model_ransac.estimator_.coef_#growth rate\n",
    "                    l0=np.exp(model_ransac.estimator_.intercept_)\n",
    "                    avscore.append(model_ransac.score(tm, dt))\n",
    "                    if(i>0):\n",
    "                        tt=peaks[i-1]+1#temporaltime\n",
    "                        tt2=peaks[i-1]-peaks[0]+1\n",
    "                        score=model_ransac.score(tm,dt)\n",
    "                        while(tt<=peaks[i]):\n",
    "                            tempCRM.append([moms[k],time[tt],l0*np.exp((-time[peaks[i-1]+1]+time[tt])*a[0]),ln[tt],a[0],score,repinx]) \n",
    "                            tempCRMsyn.append([moms[k],time[tt2],l0*np.exp((-time[peaks[i-1]+1]+time[tt])*a[0]),ln[tt],a[0],score,repinx]) \n",
    "                            tt+=1\n",
    "                            tt2+=1\n",
    "                        if(score>0.8):                        \n",
    "                            tempvf=l0*np.exp((-time[peaks[i-1]+1]+time[peaks[i]]+(tbf/2))*a[0])\n",
    "                            tempv0=l0*np.exp(-tbf*a[0]/2)\n",
    "                            if tempvf>tempv0:                            \n",
    "                                avt=(time[peaks[i-1]]+time[peaks[i]])/2\n",
    "                                timediv=-time[peaks[i-1]]+time[peaks[i]]\n",
    "                                tempv.append([tempv0,tempvf,tempvf-tempv0,a[0],avt,timediv,score,repinx])\n",
    "                                tt=peaks[i-1]+1#temporaltime\n",
    "                                if(model_ransac.score(tm,dt)>fitthresh):\n",
    "                                    coor.append([time[peaks[i]],pixelsize*ln[peaks[i]],model_ransac.score(tm,dt)])\n",
    "                        tt=peaks[i-1]+1#temporaltime\n",
    "                        score=model_ransac.score(tm,dt)\n",
    "                            \n",
    "                                \n",
    "                    else:\n",
    "                        tt=0\n",
    "                        score=model_ransac.score(tm,dt)\n",
    "                        while(tt<=peaks[i]):\n",
    "                            tempCRM.append([moms[k],time[tt],l0*np.exp((-time[0]+time[tt])*a[0]),ln[tt],a[0],score,repinx]) \n",
    "                            tt=tt+1 \n",
    "            peaksval=np.array(peaksval)\n",
    "        if len(tempv)>4:\n",
    "            fitl=[]\n",
    "            fitt=[]\n",
    "            for gg in tempCRM:     \n",
    "                if len(CRMdata)==0:\n",
    "                    CRMdata=[gg]\n",
    "                else:\n",
    "                    CRMdata=np.concatenate((CRMdata,[gg]),axis=0)\n",
    "                \n",
    "                fitl.append(gg[2])\n",
    "                fitt.append(gg[1])\n",
    "            for gg in tempCRMsyn:     \n",
    "                if len(CRMdatasyn)==0:\n",
    "                    CRMdatasyn=[gg]\n",
    "                else:\n",
    "                    CRMdatasyn=np.concatenate((CRMdatasyn,[gg]),axis=0)\n",
    "            for pp in tempv:\n",
    "                if len(DSMdata)==0:\n",
    "                    DSMdata=[pp]\n",
    "                else:\n",
    "                    DSMdata=np.concatenate((DSMdata,[pp]),axis=0)\n",
    "    print(repinx)\n",
    "    repinx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(DSMdata,columns=[\"Sb\",\"Sd\",\"Added\",\"gr\",\"timediv\",\"timecycle\",\"score\",\"Replica\"])\n",
    "dataf=pd.DataFrame(columns=[\"Sb\",\"Sd\",\"Added\",\"gr\",\"timediv\",\"timecycle\",\"score\",\"Replica\"])\n",
    "Rep=df.Replica.unique()\n",
    "for r in Rep:\n",
    "    df2=df[df.Replica==r]\n",
    "    sz=np.mean(df2.Sb)\n",
    "    dftemp=pd.DataFrame(columns=[\"Sb\",\"Sd\",\"Added\",\"gr\",\"timediv\",\"timecycle\",\"score\",\"Replica\"])\n",
    "    dftemp['Sb']=df2.Sb/sz\n",
    "    dftemp['Sd']=df2.Sd/sz\n",
    "    dftemp['Added']=df2.Sb/sz\n",
    "    dftemp['gr']=df2.gr\n",
    "    dftemp['timediv']=df2.timediv\n",
    "    dftemp['timecycle']=df2.timecycle*np.mean(df2.gr)/np.log(2)\n",
    "    dftemp['score']=df2.score\n",
    "    dftemp['Replica']=df2.Replica\n",
    "    dataf=pd.concat([dataf,dftemp])\n",
    "    #df.loc[df.Replica==r,'Sb':]*=1/sz\n",
    "    #df.loc[df.Replica==r,'Sb':]*=1/np.mean(df2.Sb)\n",
    "    #df.loc[df.Replica==r,'Sd':]*=1/np.mean(df2.Sb)\n",
    "    #df.loc[df.Replica==r,'Added':]*=1/np.mean(df2.Sb)\n",
    "    \n",
    "df=dataf\n",
    "df=df[np.abs(scipy.stats.zscore(df.Sd))<3.5]\n",
    "df=df[np.abs(scipy.stats.zscore(df.Sb))<3.5]\n",
    "df=df[np.abs(scipy.stats.zscore(df.Added))<3.5]\n",
    "df=df[np.abs(scipy.stats.zscore(df.gr))<3.5]\n",
    "df=df[np.abs(scipy.stats.zscore(df.timecycle))<4]\n",
    "df=df[df.score>0.8]\n",
    "\n",
    "\n",
    "df.to_csv(\"./DSMdataSizer.csv\",index=False)\n",
    "\n",
    "#df.to_csv(\"./DSMdataAdder.csv\",index=False)\n",
    "df=pd.DataFrame(CRMdata,columns=[\"Mother\",\"time\",\"SizeFit\",\"Size\",\"gr\",\"score\",\"Replica\"])\n",
    "szs=[19,17.3,18]\n",
    "dataf=pd.DataFrame(columns=[\"Mother\",\"time\",\"SizeFit\",\"Size\",\"gr\",\"score\",\"Replica\"])\n",
    "Rep=df.Replica.unique()\n",
    "i=0\n",
    "for r in Rep:\n",
    "    df2=df[df.Replica==r]\n",
    "    sz=szs[i]\n",
    "    dftemp=df2\n",
    "    dftemp['SizeFit']=dftemp.SizeFit/sz\n",
    "    dftemp['Size']=dftemp.Size/sz\n",
    "    i+=1\n",
    "    dataf=pd.concat([dataf,dftemp])\n",
    "df=dataf\n",
    "df.to_csv(\"./CRMdataSizer.csv\",index=False)\n",
    "df=pd.DataFrame(CRMdatasyn,columns=[\"Mother\",\"time\",\"SizeFit\",\"Size\",\"gr\",\"score\",\"Replica\"])\n",
    "szs=[19,17.3,18]\n",
    "dataf=pd.DataFrame(columns=[\"Mother\",\"time\",\"SizeFit\",\"Size\",\"gr\",\"score\",\"Replica\"])\n",
    "Rep=df.Replica.unique()\n",
    "i=0\n",
    "for r in Rep:\n",
    "    df2=df[df.Replica==r]\n",
    "    sz=szs[i]\n",
    "    dftemp=df2\n",
    "    dftemp['SizeFit']=dftemp.SizeFit/sz\n",
    "    dftemp['Size']=dftemp.Size/sz\n",
    "    i+=1\n",
    "    dataf=pd.concat([dataf,dftemp])\n",
    "df=dataf\n",
    "df.to_csv(\"./CRMdataSizersyn.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:/Users/cesar/Documents/biofisica/sizerdata/CRMdataSizersyn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:/Users/cesar/Documents/biofisica/sizerdata/CRMdataSizersyn.csv\")\n",
    "#meanarr=[19,17,18]\n",
    "#i=0\n",
    "for r in [1,2,3]:\n",
    "    df=data[data.Replica==r]\n",
    "    tarray=np.sort(df.time.unique())\n",
    "    #print(tarray)\n",
    "    meansz4=[]\n",
    "    errorsz4=[]\n",
    "    meancv2sz4=[]\n",
    "    errorcv2sz4=[]\n",
    "    tarray4=[]\n",
    "    for t in tarray:\n",
    "        dft=df[df.time==t]\n",
    "        #print(dft)\n",
    "        if (len(dft)>2):\n",
    "#        timecorrect.append(t)\n",
    "            mean_cntr, var_cntr, std_cntr = bayesest(dft.Size,alpha=0.95)\n",
    "            meansz4.append(mean_cntr[0])\n",
    "            errorsz4.append(mean_cntr[1][1]-mean_cntr[0])\n",
    "            meancv2sz4.append(var_cntr[0]/mean_cntr[0]**2)\n",
    "            errv=(var_cntr[1][1]-var_cntr[0])/mean_cntr[0]**2+2*(mean_cntr[1][1]-mean_cntr[0])*var_cntr[0]/mean_cntr[0]**3\n",
    "            errorcv2sz4.append(errv)\n",
    "            tarray4.append(t)\n",
    "            #errorcv2gr.append((std_cntr[1][1]-std_cntr[0])/mean_cntr[0]+(mean_cntr[1][1]-mean_cntr[0])*std_cntr[0]/(mean_cntr[0])**2)\n",
    "    plt.plot(tarray4,meansz4,lw=3)\n",
    "    plt.fill_between(tarray4, np.array(meansz4)+np.array(errorsz4), np.array(meansz4)-np.array(errorsz4),alpha=1, edgecolor='#4db8ff', facecolor='#4db8ff',\n",
    "    linewidth=0)\n",
    "    i+=1\n",
    "#plt.xlim(0,6)\n",
    "#plt.ylim(1,1.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:/Users/cesar/Documents/biofisica/sizerdata/CRMdataSizer.csv\")\n",
    "meanarr=[18,18,19.2]\n",
    "i=0\n",
    "for r in [1,2,3]:\n",
    "    df=data[data.Replica==r]\n",
    "    tarray=np.sort(df.time.unique())\n",
    "    #print(tarray)\n",
    "    meansz4=[]\n",
    "    errorsz4=[]\n",
    "    meancv2sz4=[]\n",
    "    errorcv2sz4=[]\n",
    "    tarray4=[]\n",
    "    for t in tarray:\n",
    "        dft=df[df.time==t]\n",
    "        #print(dft)\n",
    "        if (len(dft)>2):\n",
    "#        timecorrect.append(t)\n",
    "            mean_cntr, var_cntr, std_cntr = bayesest(dft.Size,alpha=0.95)\n",
    "            meansz4.append(mean_cntr[0])\n",
    "            errorsz4.append(mean_cntr[1][1]-mean_cntr[0])\n",
    "            meancv2sz4.append(var_cntr[0]/mean_cntr[0]**2)\n",
    "            errv=(var_cntr[1][1]-var_cntr[0])/mean_cntr[0]**2+2*(mean_cntr[1][1]-mean_cntr[0])*var_cntr[0]/mean_cntr[0]**3\n",
    "            errorcv2sz4.append(errv)\n",
    "            tarray4.append(t)\n",
    "            #errorcv2gr.append((std_cntr[1][1]-std_cntr[0])/mean_cntr[0]+(mean_cntr[1][1]-mean_cntr[0])*std_cntr[0]/(mean_cntr[0])**2)\n",
    "    plt.plot(tarray4,meansz4,lw=3)\n",
    "    plt.fill_between(tarray4, np.array(meansz4)+np.array(errorsz4), np.array(meansz4)-np.array(errorsz4),alpha=1, edgecolor='#4db8ff', facecolor='#4db8ff',\n",
    "    linewidth=0)\n",
    "    i+=1\n",
    "#plt.xlim(0,6)\n",
    "#plt.ylim(1,1.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "data=pd.read_csv(\"C:/Users/cesar/Documents/biofisica/sizerdata/CRMdataSizer.csv\")\n",
    "data=data[data.score>0.8]\n",
    "for rep in [1,2,3]:\n",
    "    df=data[data.Replica==rep]\n",
    "    tarray=np.sort(df.time.unique())\n",
    "    meangr=[]\n",
    "    errorgr=[]\n",
    "    meancv2gr=[]\n",
    "    errorcv2gr=[]\n",
    "    for t in tarray:\n",
    "        dft=df[df.time==t]\n",
    "        if (len(df)>1):\n",
    "#        timecorrect.append(t)\n",
    "            mean_cntr, var_cntr, std_cntr = bayesest(dft.gr,alpha=0.95)\n",
    "            meangr.append(mean_cntr[0])\n",
    "            errorgr.append(mean_cntr[1][1]-mean_cntr[0])\n",
    "            meancv2gr.append(var_cntr[0]/mean_cntr[0]**2)\n",
    "            errv=(var_cntr[1][1]-var_cntr[0])/mean_cntr[0]**2+2*(mean_cntr[1][1]-mean_cntr[0])*var_cntr[0]/mean_cntr[0]**3\n",
    "            errorcv2gr.append(errv)\n",
    "            #errorcv2gr.append((std_cntr[1][1]-std_cntr[0])/mean_cntr[0]+(mean_cntr[1][1]-mean_cntr[0])*std_cntr[0]/(mean_cntr[0])**2)\n",
    "    plt.plot(tarray,meangr,lw=3)\n",
    "    plt.fill_between(tarray, np.array(meangr)+np.array(errorgr), np.array(meangr)-np.array(errorgr),alpha=1, edgecolor='#4db8ff', facecolor='#4db8ff',\n",
    "    linewidth=0)\n",
    "#plt.ylim([0,0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorcor(x,y):\n",
    "    meanar=[]\n",
    "    varar=[]\n",
    "    for m in range(100):\n",
    "        bstx=[]\n",
    "        bsty=[]\n",
    "        for m in range(len(x)):\n",
    "            r=np.random.randint(len(x))\n",
    "            bstx.append(x[r])\n",
    "            bstx.append(y[r])\n",
    "        meanar.append(np.corrcoef(xx,yy)[0][1])\n",
    "\n",
    "\n",
    "    confmn=(np.abs(np.percentile(meanar,5)-np.mean(meanar))+np.abs(np.percentile(meanar,95)-np.mean(meanar)))/2\n",
    "    return [np.mean(meanar),confmn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./CRMdataSizersyn.csv\")\n",
    "data=data[data.Replica!=1]\n",
    "taumax=50\n",
    "tauarr5=range(taumax)\n",
    "tarr=data.time.tolist()\n",
    "corarr5=[]\n",
    "errorcorr5=[]\n",
    "for tau in tauarr5:\n",
    "    print(tau)\n",
    "    xx=[]\n",
    "    yy=[]\n",
    "    for i in np.arange(0,20,2):\n",
    "        \n",
    "        df=data[data.time==tarr[i]]\n",
    "        datamom1=df.Mother.unique()\n",
    "        del df['time']\n",
    "        df2=data[data.time==tarr[i+tau]]\n",
    "        datamom2=df2.Mother.unique()\n",
    "        allmom=[]\n",
    "        A=[]\n",
    "        B=[]\n",
    "        for m in datamom1:\n",
    "            if m in datamom2:\n",
    "                A.append(df[df.Mother==m].Size.tolist()[0])\n",
    "                B.append(df2[df2.Mother==m].Size.tolist()[0])\n",
    "        del df2['time']\n",
    "\n",
    "        \n",
    "        for m in range(len(A)):\n",
    "            xx.append(A[m])\n",
    "        for m in range(len(A)):\n",
    "            yy.append(B[m])\n",
    "        #xx.append()\n",
    "        #yy.append(df2.tolist())\n",
    "    #print(len(xx))\n",
    "    corarr5.append(errorcor(xx,yy)[0])\n",
    "    errorcorr5.append(errorcor(xx,yy)[1])\n",
    "#inspace(0,3.15,len(corarr2)),corarr2,label=\"Experiment\",c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyEcoLib.simulator import Simulator\n",
    "\n",
    "div_steps=10\n",
    "CV2sz = 0.04\n",
    "CV2div = 0.01\n",
    "CV2gr = 0.017\n",
    "v0 = mean_size*np.random.gamma(shape=1/CV2sz,scale=CV2sz,size=ncells)\n",
    "sim = Simulator(ncells=ncells, gr = gr, sb=mean_size, steps = div_steps, CV2div = CV2div, CV2gr = CV2gr,V0array=v0,lamb=1.5)\n",
    "sim.szdyn(tmax = tmax, sample_time= 0.1*doubling_time, nameCRM = \"./dataCRM4.csv\")\n",
    "#print('It took', np.int(time.time()-start), 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./dataCRM4.csv\")\n",
    "taumax=60\n",
    "tauarr4=range(taumax)\n",
    "tarr=data.time.tolist()\n",
    "corarr4=[]\n",
    "for tau in tauarr4:\n",
    "    xx=[]\n",
    "    yy=[]\n",
    "    for i in range(30):\n",
    "        df=data[data.time==tarr[i]]\n",
    "        del df['time']\n",
    "        df2=data[data.time==tarr[i+tau]]\n",
    "        del df2['time']\n",
    "        print\n",
    "        #print(df.iloc[0].tolist())\n",
    "        A=df.iloc[0].tolist()\n",
    "        B=df2.iloc[0].tolist()\n",
    "        for m in range(len(A)):\n",
    "            xx.append(A[m])\n",
    "        for m in range(len(A)):\n",
    "            yy.append(B[m])\n",
    "        #xx.append()\n",
    "        #yy.append(df2.tolist())\n",
    "    #print(len(xx))\n",
    "    corarr4.append(np.corrcoef(xx,yy)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(tauarr4)/10,corarr4)\n",
    "plt.errorbar(np.array(tauarr5)/9,corarr5,yerr=errorcorr5,\n",
    "                               color='#008658',capsize=3,fmt='o',markersize='5',elinewidth=2)\n",
    "\n",
    "plt.xlim(0,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv(\"./dataCRM4.csv\")\n",
    "timearray4=data1.time.unique()\n",
    "\n",
    "mnszarray4=[]\n",
    "cvszarray4=[]\n",
    "errcv2sz4=[]\n",
    "errmnsz4=[]\n",
    "df=data1\n",
    "del df['time']\n",
    "for m in range(len(df)):\n",
    "    szs=df.loc[m, :].values.tolist()\n",
    "    mean_cntr, var_cntr, std_cntr = bayesest(szs,alpha=0.95)\n",
    "    mnszarray4.append(np.mean(szs))\n",
    "    errmnsz4.append(mean_cntr[1][1]-mean_cntr[0])\n",
    "    cvszarray4.append(np.var(szs)/np.mean(szs)**2)\n",
    "    errv=(var_cntr[1][1]-var_cntr[0])/mean_cntr[0]**2+2*(mean_cntr[1][1]-mean_cntr[0])*var_cntr[0]/mean_cntr[0]**3\n",
    "    errcv2sz4.append(errv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./CRMdataSizersyn.csv\")\n",
    "data=data[data.Replica!=1]\n",
    "df=data\n",
    "tarray=np.sort(df.time.unique())\n",
    "meansz4=[]\n",
    "errorsz4=[]\n",
    "meancv2sz4=[]\n",
    "errorcv2sz4=[]\n",
    "tarray4=[]\n",
    "for t in tarray:\n",
    "    dft=df[df.time==t]\n",
    "        #print(dft)\n",
    "    if (len(dft)>2):\n",
    "#        timecorrect.append(t)\n",
    "        #print(len(dft))\n",
    "        mean_cntr, var_cntr, std_cntr = bayesest(1.12*dft.Size,alpha=0.95)\n",
    "        meansz4.append(mean_cntr[0])\n",
    "        errorsz4.append(mean_cntr[1][1]-mean_cntr[0])\n",
    "        meancv2sz4.append(var_cntr[0]/mean_cntr[0]**2)\n",
    "        errv=(var_cntr[1][1]-var_cntr[0])/mean_cntr[0]**2+2*(mean_cntr[1][1]-mean_cntr[0])*var_cntr[0]/mean_cntr[0]**3\n",
    "        errorcv2sz4.append(errv)\n",
    "        tarray4.append(t)        #errorcv2gr.append((std_cntr[1][1]-std_cntr[0])/mean_cntr[0]+(mean_cntr[1][1]-mean_cntr[0])*std_cntr[0]/(mean_cntr[0])**2)\n",
    "plt.errorbar((np.array(tarray4)-1.5)/(18),meansz4,yerr=errorsz4,\n",
    "                               color='#008658',capsize=3,fmt='o',markersize='3',elinewidth=2)\n",
    "plt.fill_between(np.array(timearray4)/10,np.array(mnszarray4)-np.array(errmnsz4),np.array(mnszarray4)\n",
    "                 +np.array(errmnsz4),alpha=1, edgecolor='#4db8ff', facecolor='#4db8ff',linewidth=0)\n",
    "    #        plt.scatter(tarray,meansz,lw=3)\n",
    "    #plt.fill_between(tarray, np.array(meansz)+np.array(errorsz), np.array(meansz)-np.array(errorsz),alpha=1, edgecolor='#4db8ff', facecolor='#4db8ff',\n",
    "    #linewidth=0)\n",
    "plt.xlim(0,8)\n",
    "#plt.ylim(0,0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./CRMdataSizersyn.csv\")\n",
    "data=data[data.Replica!=1]\n",
    "df=data\n",
    "tarray=np.sort(df.time.unique())\n",
    "meansz4=[]\n",
    "errorsz4=[]\n",
    "meancv2sz4=[]\n",
    "errorcv2sz4=[]\n",
    "tarray4=[]\n",
    "for t in tarray:\n",
    "    dft=df[df.time==t]\n",
    "        #print(dft)\n",
    "    if (len(dft)>2):\n",
    "#        timecorrect.append(t)\n",
    "        print(len(dft))\n",
    "        mean_cntr, var_cntr, std_cntr = bayesest(dft.Size,alpha=0.95)\n",
    "        meansz4.append(mean_cntr[0])\n",
    "        errorsz4.append(mean_cntr[1][1]-mean_cntr[0])\n",
    "        meancv2sz4.append(var_cntr[0]/mean_cntr[0]**2)\n",
    "        errv=(var_cntr[1][1]-var_cntr[0])/mean_cntr[0]**2+2*(mean_cntr[1][1]-mean_cntr[0])*var_cntr[0]/mean_cntr[0]**3\n",
    "        errorcv2sz4.append(errv)\n",
    "        tarray4.append(t)        #errorcv2gr.append((std_cntr[1][1]-std_cntr[0])/mean_cntr[0]+(mean_cntr[1][1]-mean_cntr[0])*std_cntr[0]/(mean_cntr[0])**2)\n",
    "plt.errorbar((np.array(tarray4)-1.5)/18,meancv2sz4,yerr=errorcv2sz4,\n",
    "                               color='#008658',capsize=3,fmt='o',markersize='3',elinewidth=2)\n",
    "plt.fill_between(np.array(timearray4)/10,np.array(cvszarray4)-np.array(errcv2sz4),np.array(cvszarray4)\n",
    "                   +np.array(errcv2sz4),alpha=1, edgecolor='#4db8ff', facecolor='#4db8ff',linewidth=0)\n",
    "    #        plt.scatter(tarray,meansz,lw=3)\n",
    "    #plt.fill_between(tarray, np.array(meansz)+np.array(errorsz), np.array(meansz)-np.array(errorsz),alpha=1, edgecolor='#4db8ff', facecolor='#4db8ff',\n",
    "    #linewidth=0)\n",
    "plt.xlim(0,8)\n",
    "plt.ylim(0,0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV2sz = 0.01\n",
    "CV2div = 0\n",
    "CV2gr = 0\n",
    "\n",
    "div_steps=15\n",
    "v0 = mean_size*np.random.gamma(shape=1/CV2sz,scale=CV2sz,size=ncells)\n",
    "sim = Simulator(ncells=ncells, gr = gr, sb=mean_size, steps = div_steps, CV2div = CV2div, CV2gr = CV2gr,V0array=v0)\n",
    "sim.szdyn(tmax = tmax, sample_time= 0.1*doubling_time, nameCRM = \"./dataCRM6.csv\")\n",
    "sim.szdynFSP(tmax = tmax, nameFSP = \"./dataFSP6.csv\",CV2sz=CV2sz) \n",
    "#print('It took', np.int(time.time()-start), 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv(\"./dataCRM6.csv\")\n",
    "timearray6=data1.time.unique()\n",
    "\n",
    "mnszarray6=[]\n",
    "cvszarray6=[]\n",
    "errcv2sz6=[]\n",
    "errmnsz6=[]\n",
    "df=data1\n",
    "del df['time']\n",
    "for m in range(len(df)):\n",
    "    szs=df.loc[m, :].values.tolist()\n",
    "    mean_cntr, var_cntr, std_cntr = bayesest(szs,alpha=0.95)\n",
    "    mnszarray6.append(np.mean(szs))\n",
    "    errmnsz6.append(mean_cntr[1][1]-mean_cntr[0])\n",
    "    cvszarray6.append(np.var(szs)/np.mean(szs)**2)\n",
    "    errv=(var_cntr[1][1]-var_cntr[0])/mean_cntr[0]**2+2*(mean_cntr[1][1]-mean_cntr[0])*var_cntr[0]/mean_cntr[0]**3\n",
    "    errcv2sz6.append(errv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./dataCRM6.csv\")\n",
    "taumax=60\n",
    "tauarr6=range(taumax)\n",
    "tarr=data.time.tolist()\n",
    "corarr6=[]\n",
    "for tau in tauarr6:\n",
    "    xx=[]\n",
    "    yy=[]\n",
    "    for i in range(30):\n",
    "        df=data[data.time==tarr[i]]\n",
    "        del df['time']\n",
    "        df2=data[data.time==tarr[i+tau]]\n",
    "        del df2['time']\n",
    "        print\n",
    "        #print(df.iloc[0].tolist())\n",
    "        A=df.iloc[0].tolist()\n",
    "        B=df2.iloc[0].tolist()\n",
    "        for m in range(len(A)):\n",
    "            xx.append(A[m])\n",
    "        for m in range(len(A)):\n",
    "            yy.append(B[m])\n",
    "        #xx.append()\n",
    "        #yy.append(df2.tolist())\n",
    "    #print(len(xx))\n",
    "    corarr6.append(np.corrcoef(xx,yy)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV2sz = 0.01\n",
    "CV2div = 0.01\n",
    "CV2gr = 0.02\n",
    "\n",
    "div_steps=15\n",
    "v0 = mean_size*np.random.gamma(shape=1/CV2sz,scale=CV2sz,size=ncells)\n",
    "sim = Simulator(ncells=ncells, gr = gr, sb=mean_size, steps = div_steps, CV2div = CV2div, CV2gr = CV2gr,V0array=v0)\n",
    "sim.szdyn(tmax = tmax, sample_time= 0.1*doubling_time, nameCRM = \"./dataCRM7.csv\")\n",
    "#sim.szdynFSP(tmax = tmax, nameFSP = \"./dataFSP7.csv\",CV2sz=CV2sz) \n",
    "#print('It took', np.int(time.time()-start), 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv(\"./dataCRM7.csv\")\n",
    "timearray7=data1.time.unique()\n",
    "\n",
    "mnszarray7=[]\n",
    "cvszarray7=[]\n",
    "errcv2sz7=[]\n",
    "errmnsz7=[]\n",
    "df=data1\n",
    "del df['time']\n",
    "for m in range(len(df)):\n",
    "    szs=df.loc[m, :].values.tolist()\n",
    "    mean_cntr, var_cntr, std_cntr = bayesest(szs,alpha=0.95)\n",
    "    mnszarray7.append(np.mean(szs))\n",
    "    errmnsz7.append(mean_cntr[1][1]-mean_cntr[0])\n",
    "    cvszarray7.append(np.var(szs)/np.mean(szs)**2)\n",
    "    errv=(var_cntr[1][1]-var_cntr[0])/mean_cntr[0]**2+2*(mean_cntr[1][1]-mean_cntr[0])*var_cntr[0]/mean_cntr[0]**3\n",
    "    errcv2sz7.append(errv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./dataCRM7.csv\")\n",
    "taumax=60\n",
    "tauarr7=range(taumax)\n",
    "tarr=data.time.tolist()\n",
    "corarr7=[]\n",
    "for tau in tauarr7:\n",
    "    xx=[]\n",
    "    yy=[]\n",
    "    for i in range(30):\n",
    "        df=data[data.time==tarr[i]]\n",
    "        del df['time']\n",
    "        df2=data[data.time==tarr[i+tau]]\n",
    "        del df2['time']\n",
    "        print\n",
    "        #print(df.iloc[0].tolist())\n",
    "        A=df.iloc[0].tolist()\n",
    "        B=df2.iloc[0].tolist()\n",
    "        for m in range(len(A)):\n",
    "            xx.append(A[m])\n",
    "        for m in range(len(A)):\n",
    "            yy.append(B[m])\n",
    "        #xx.append()\n",
    "        #yy.append(df2.tolist())\n",
    "    #print(len(xx))\n",
    "    corarr7.append(np.corrcoef(xx,yy)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,3, figsize=(18,12))\n",
    "\n",
    "ax[0,0].fill_between(timearray6/18, np.array(mnszarray6)+np.array(errmnsz6), np.array(mnszarray6)\n",
    "                     -np.array(errmnsz6),alpha=1, edgecolor='#FF2776', facecolor='#FF2776',\n",
    "    linewidth=0,label=\"Stochastic Division (SSA)\")    #        plt.scatter(tarray,meansz,lw=3)\n",
    "    #plt.fill_between(tarray, np.array(meansz)+np.array(errorsz), np.array(meansz)-np.array(errorsz),alpha=1, edgecolor='#4db8ff', facecolor='#4db8ff',\n",
    "    #linewidth=0)\n",
    "ax[0,0].set_xlim(0,5)\n",
    "ax[0,0].set_ylim(0.9,1.8)\n",
    "\n",
    "ax[1,0].fill_between(np.array(timearray6)/18,np.array(cvszarray6)-np.array(errcv2sz6),np.array(cvszarray6)\n",
    "                   +np.array(errcv2sz6),alpha=1, edgecolor='#FF2776', facecolor='#FF2776',linewidth=0)\n",
    " \n",
    "data=pd.read_csv(\"./dataFSP6.csv\")\n",
    "ax[0,0].plot(data.time/doubling_time,data.Meansize,ls='--',c='k',label=\"Numerical\",lw=2)\n",
    "ax[1,0].plot(data.time/doubling_time,data.VarSize/data.Meansize**2,ls='--',c='k',lw=2)\n",
    "\n",
    "ax[1,0].set_xlim(0,5)\n",
    "#ax[0,0].set_ylim(0.9,1.8)\n",
    "\n",
    "ax[2,0].plot(np.array(tauarr6)/10,corarr6,lw=3,c='#FF2776')\n",
    "ax[1,0].set_ylim(0.0,0.14)\n",
    "\n",
    "#____________________________________________________\n",
    "ax[0,0].fill_between(timearray6/18, np.array(mnszarray7)+np.array(errmnsz7), np.array(mnszarray7)\n",
    "                     -np.array(errmnsz7),alpha=1, edgecolor='#0065D3', facecolor='#0065D3',\n",
    "    linewidth=0,label=\"Additional Noise (SSA)\")    #        plt.scatter(tarray,meansz,lw=3)\n",
    "    #plt.fill_between(tarray, np.array(meansz)+np.array(errorsz), np.array(meansz)-np.array(errorsz),alpha=1, edgecolor='#4db8ff', facecolor='#4db8ff',\n",
    "    #linewidth=0)\n",
    "ax[0,0].set_xlim(0,5)\n",
    "ax[0,0].set_ylim(0.9,1.8)\n",
    "\n",
    "ax[1,0].fill_between(np.array(timearray7)/18,np.array(cvszarray7)-np.array(errcv2sz7),np.array(cvszarray7)\n",
    "                   +np.array(errcv2sz7),alpha=1, edgecolor='#0065D3', facecolor='#0065D3',linewidth=0)\n",
    " \n",
    "\n",
    "ax[1,0].set_xlim(0,5)\n",
    "#ax[0,0].set_ylim(0.9,1.8)\n",
    "\n",
    "ax[2,0].plot(np.array(tauarr7)/10,corarr7,c='#0065D3',lw=3)\n",
    "ax[1,0].set_ylim(0.0,0.14)\n",
    "#_____________________________________________________________\n",
    "\n",
    "\n",
    "data=pd.read_csv(\"./CRMdataAddersyn.csv\")\n",
    "df=data\n",
    "tarray=np.sort(df.time.unique())\n",
    "meansz=[]\n",
    "errorsz=[]\n",
    "meancv2sz=[]\n",
    "errorcv2sz=[]\n",
    "for t in tarray:\n",
    "    dft=df[df.time==t]\n",
    "    if (len(df)>1):\n",
    "#        timecorrect.append(t)\n",
    "        mean_cntr, var_cntr, std_cntr = bayesest(dft.Size,alpha=0.95)\n",
    "        meansz.append(mean_cntr[0])\n",
    "        errorsz.append(mean_cntr[1][1]-mean_cntr[0])\n",
    "        meancv2sz.append(var_cntr[0]/mean_cntr[0]**2)\n",
    "        errv=(var_cntr[1][1]-var_cntr[0])/mean_cntr[0]**2+2*(mean_cntr[1][1]-mean_cntr[0])*var_cntr[0]/mean_cntr[0]**3\n",
    "        errorcv2sz.append(errv)\n",
    "            #errorcv2gr.append((std_cntr[1][1]-std_cntr[0])/mean_cntr[0]+(mean_cntr[1][1]-mean_cntr[0])*std_cntr[0]/(mean_cntr[0])**2)\n",
    "ax[0,1].errorbar((np.array(tarray)-0.2),(np.array(meansz)+0.05),mec='#016400',yerr=errorcv2sz,\n",
    "                               color='#008658',capsize=3,fmt='o',markersize='5',elinewidth=2,label=\"Experiment\")\n",
    "ax[0,1].fill_between(timearray3/18, np.array(mnszarray3)+np.array(errmnsz3), np.array(mnszarray3)-np.array(errmnsz3),\n",
    "                     alpha=1, edgecolor='#0065D3', facecolor='#0065D3',    linewidth=0,label=\"SSA\")    #        plt.scatter(tarray,meansz,lw=3)\n",
    "    #plt.fill_between(tarray, np.array(meansz)+np.array(errorsz), np.array(meansz)-np.array(errorsz),alpha=1, edgecolor='#4db8ff', facecolor='#4db8ff',\n",
    "    #linewidth=0)\n",
    "ax[0,1].set_xlim(0,6)\n",
    "ax[0,1].set_ylim(0.9,1.8)\n",
    "ax[1,1].set_ylim(0.0,0.14)\n",
    "\n",
    "data=pd.read_csv(\"./CRMdataSizersyn.csv\")\n",
    "data=data[data.Replica!=1]\n",
    "df=data\n",
    "tarray=np.sort(df.time.unique())\n",
    "meansz4=[]\n",
    "errorsz4=[]\n",
    "meancv2sz4=[]\n",
    "errorcv2sz4=[]\n",
    "tarray4=[]\n",
    "for t in tarray:\n",
    "    dft=df[df.time==t]\n",
    "        #print(dft)\n",
    "    if (len(dft)>2):\n",
    "#        timecorrect.append(t)\n",
    "        #print(len(dft))\n",
    "        mean_cntr, var_cntr, std_cntr = bayesest(1.12*dft.Size,alpha=0.95)\n",
    "        meansz4.append(mean_cntr[0])\n",
    "        errorsz4.append(mean_cntr[1][1]-mean_cntr[0])\n",
    "        meancv2sz4.append(var_cntr[0]/mean_cntr[0]**2)\n",
    "        errv=(var_cntr[1][1]-var_cntr[0])/mean_cntr[0]**2+2*(mean_cntr[1][1]-mean_cntr[0])*var_cntr[0]/mean_cntr[0]**3\n",
    "        errorcv2sz4.append(errv)\n",
    "        tarray4.append(t)        #errorcv2gr.append((std_cntr[1][1]-std_cntr[0])/mean_cntr[0]+(mean_cntr[1][1]-mean_cntr[0])*std_cntr[0]/(mean_cntr[0])**2)\n",
    "ax[0,2].errorbar((np.array(tarray4)-1.5)/(32),meansz4,yerr=errorsz4,mec='#016400',\n",
    "                               color='#008658',capsize=3,fmt='o',markersize='5',elinewidth=2,label=\"Experiment\")\n",
    "ax[0,2].fill_between(np.array(timearray4)/18,np.array(mnszarray4)-np.array(errmnsz4),np.array(mnszarray4)\n",
    "                 +np.array(errmnsz4),alpha=1, edgecolor='#0065D3', facecolor='#0065D3',linewidth=0,label=\"SSA\")\n",
    "    #        plt.scatter(tarray,meansz,lw=3)\n",
    "    #plt.fill_between(tarray, np.array(meansz)+np.array(errorsz), np.array(meansz)-np.array(errorsz),alpha=1, edgecolor='#4db8ff', facecolor='#4db8ff',\n",
    "    #linewidth=0)\n",
    "ax[0,2].set_xlim(0,5)\n",
    "ax[1,2].set_ylim(0.0,0.16)\n",
    "\n",
    "data=pd.read_csv(\"./CRMdataAddersyn.csv\")\n",
    "df=data\n",
    "tarray=np.sort(df.time.unique())\n",
    "meansz=[]\n",
    "errorsz=[]\n",
    "meancv2sz=[]\n",
    "errorcv2sz=[]\n",
    "for t in tarray:\n",
    "    dft=df[df.time==t]\n",
    "    if (len(df)>1):\n",
    "#        timecorrect.append(t)\n",
    "        mean_cntr, var_cntr, std_cntr = bayesest(dft.Size,alpha=0.95)\n",
    "        meansz.append(mean_cntr[0])\n",
    "        errorsz.append(mean_cntr[1][1]-mean_cntr[0])\n",
    "        meancv2sz.append(var_cntr[0]/mean_cntr[0]**2)\n",
    "        errv=(var_cntr[1][1]-var_cntr[0])/mean_cntr[0]**2+2*(mean_cntr[1][1]-mean_cntr[0])*var_cntr[0]/mean_cntr[0]**3\n",
    "        errorcv2sz.append(errv)\n",
    "            #errorcv2gr.append((std_cntr[1][1]-std_cntr[0])/mean_cntr[0]+(mean_cntr[1][1]-mean_cntr[0])*std_cntr[0]/(mean_cntr[0])**2)\n",
    "ax[1,1].errorbar((np.array(tarray)-0.2),meancv2sz,yerr=errorcv2sz,\n",
    "                               color='#008658',capsize=3,fmt='o',markersize='5',mec='#016400',elinewidth=2)\n",
    "ax[1,1].fill_between(np.array(timearray3)/18,np.array(cvszarray3)-np.array(errcv2sz3),np.array(cvszarray3)\n",
    "                   +np.array(errcv2sz3),alpha=1, edgecolor='#0065D3', facecolor='#0065D3',linewidth=0)\n",
    "    #        plt.scatter(tarray,meansz,lw=3)\n",
    "    #plt.fill_between(tarray, np.array(meansz)+np.array(errorsz), np.array(meansz)-np.array(errorsz),alpha=1, edgecolor='#4db8ff', facecolor='#4db8ff',\n",
    "    #linewidth=0)\n",
    "ax[1,1].set_xlim(0,5)\n",
    "ax[1,1].set_ylim(0.0,0.16)\n",
    "ax[0,2].set_ylim(0.9,1.8)\n",
    "ax[1,0].set_ylim(0.0,0.16)\n",
    "data=pd.read_csv(\"./CRMdataSizersyn.csv\")\n",
    "data=data[data.Replica!=1]\n",
    "df=data\n",
    "tarray=np.sort(df.time.unique())\n",
    "meansz4=[]\n",
    "errorsz4=[]\n",
    "meancv2sz4=[]\n",
    "errorcv2sz4=[]\n",
    "tarray4=[]\n",
    "for t in tarray:\n",
    "    dft=df[df.time==t]\n",
    "        #print(dft)\n",
    "    if (len(dft)>2):\n",
    "#        timecorrect.append(t)\n",
    "        #print(len(dft))\n",
    "        mean_cntr, var_cntr, std_cntr = bayesest(dft.Size,alpha=0.95)\n",
    "        meansz4.append(mean_cntr[0])\n",
    "        errorsz4.append(mean_cntr[1][1]-mean_cntr[0])\n",
    "        meancv2sz4.append(var_cntr[0]/mean_cntr[0]**2)\n",
    "        errv=(var_cntr[1][1]-var_cntr[0])/mean_cntr[0]**2+2*(mean_cntr[1][1]-mean_cntr[0])*var_cntr[0]/mean_cntr[0]**3\n",
    "        errorcv2sz4.append(errv)\n",
    "        tarray4.append(t)        #errorcv2gr.append((std_cntr[1][1]-std_cntr[0])/mean_cntr[0]+(mean_cntr[1][1]-mean_cntr[0])*std_cntr[0]/(mean_cntr[0])**2)\n",
    "ax[1,2].errorbar((np.array(tarray4)-1.5)/(32),meancv2sz4,yerr=errorcv2sz4,\n",
    "                               color='#008658',capsize=3,fmt='o',markersize='5',mec='#016400',elinewidth=2)\n",
    "ax[1,2].fill_between(np.array(timearray4)/18,np.array(cvszarray4)-np.array(errcv2sz4),np.array(cvszarray4)\n",
    "                   +np.array(errcv2sz4),alpha=1, edgecolor='#0065D3', facecolor='#0065D3',linewidth=0)\n",
    "    #        plt.scatter(tarray,meansz,lw=3)\n",
    "    #plt.fill_between(tarray, np.array(meansz)+np.array(errorsz), np.array(meansz)-np.array(errorsz),alpha=1, edgecolor='#4db8ff', facecolor='#4db8ff',\n",
    "    #linewidth=0)\n",
    "ax[1,2].set_xlim(0,5)\n",
    "ax[1,2].set_ylim(0,0.16)\n",
    "\n",
    "ax[2,1].plot(np.array(tauarr3)/10,corarr3,lw=3)\n",
    "ax[2,1].errorbar(np.array(tauarr2)*0.25*0.95,corarr2,yerr=np.zeros(len(corarr2)),\n",
    "                               color='#008658',capsize=3,fmt='o',markersize='5',mec='#016400',elinewidth=2)\n",
    "ax[2,1].set_xlim(0,5)\n",
    "\n",
    "\n",
    "ax[2,2].plot(np.array(tauarr4)/10,corarr4,lw=3,c=\"#0065D3\")\n",
    "ax[2,2].errorbar(np.array(tauarr5)/9,corarr5,yerr=errorcorr5,\n",
    "                               color='#008658',capsize=3,fmt='o',markersize='5',mec='#016400',elinewidth=2)\n",
    "\n",
    "ax[2,2].set_xlim(0,5)\n",
    "ax[2,0].set_xlim(0,5)\n",
    "for i in [0,1,2]:\n",
    "    for j in [0,1,2]:\n",
    "        ax[i,j].grid()\n",
    "        ax[i,j].tick_params(axis='x', labelsize=15)\n",
    "        ax[i,j].tick_params(axis='y', labelsize=15)\n",
    "        for axis in ['top','bottom','left','right']:\n",
    "            ax[i,j].spines[axis].set_linewidth(2)\n",
    "            ax[i,j].tick_params(axis='both', width=2,length=6)\n",
    "        #ax[i].legend(fontsize=15)\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "plt.subplots_adjust(wspace=0.25)\n",
    "\n",
    "ax[0,0].set_ylabel(r'$\\langle s \\rangle/\\overline{s_b}$',size=20)\n",
    "ax[1,0].set_ylabel(r'$ C_v^2(s)$',size=20)\n",
    "ax[2,0].set_ylabel(r'$ \\gamma(t) $',size=20)\n",
    "\n",
    "ax[2,0].set_xlabel(r'$t/\\tau$',size=20)\n",
    "ax[2,1].set_xlabel(r'$t/\\tau$',size=20)\n",
    "ax[2,2].set_xlabel(r'$t/\\tau$',size=20)\n",
    "\n",
    "ax[0,0].set_title(\"Theoretical\",size=20)\n",
    "ax[0,1].set_title(\"Glucose\",size=20)\n",
    "ax[0,2].set_title(\"Glycerol\",size=20)\n",
    "ax[0,0].legend(fontsize=15)\n",
    "ax[0,1].legend(fontsize=15)\n",
    "ax[0,2].legend(fontsize=15)\n",
    "\n",
    "ax[0,0].text(-1,1.8,\"A.\",fontsize=20)\n",
    "ax[0,1].text(-1,1.8,\"B.\",fontsize=20)\n",
    "ax[0,2].text(-1,1.8,\"C.\",fontsize=20)\n",
    "ax[1,0].text(-1,0.16,\"D.\",fontsize=20)\n",
    "ax[1,1].text(-1,0.16,\"E.\",fontsize=20)\n",
    "ax[1,2].text(-1,0.16,\"F.\",fontsize=20)\n",
    "ax[2,0].text(-1,1.1,\"G.\",fontsize=20)\n",
    "ax[2,1].text(-1,1.1,\"H.\",fontsize=20)\n",
    "ax[2,2].text(-1,1.1,\"I.\",fontsize=20)\n",
    "\n",
    "plt.savefig('./OscPan.eps',bbox_inches='tight',dpi=600)\n",
    "plt.savefig('./OscPan.svg',bbox_inches='tight',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv(\"./CRMdataAddersyn.csv\")\n",
    "timearray7=data1.time.unique()\n",
    "\n",
    "mnszarray7=[]\n",
    "cvszarray7=[]\n",
    "errcv2sz7=[]\n",
    "errmnsz7=[]\n",
    "df=data1\n",
    "del df['time']\n",
    "for m in range(len(df)):\n",
    "    szs=df.loc[m, :].values.tolist()\n",
    "    mean_cntr, var_cntr, std_cntr = bayesest(szs,alpha=0.95)\n",
    "    mnszarray7.append(np.mean(szs))\n",
    "    errmnsz7.append(mean_cntr[1][1]-mean_cntr[0])\n",
    "    cvszarray7.append(np.var(szs)/np.mean(szs)**2)\n",
    "    errv=(var_cntr[1][1]-var_cntr[0])/mean_cntr[0]**2+2*(mean_cntr[1][1]-mean_cntr[0])*var_cntr[0]/mean_cntr[0]**3\n",
    "    errcv2sz7.append(errv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv(\"./CRMdataAddersyn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data1.Mother.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./CRMdataAddersyn.csv\")\n",
    "df=data\n",
    "tarray=np.sort(df.time.unique())\n",
    "meansz=[]\n",
    "errorsz=[]\n",
    "meancv2sz=[]\n",
    "errorcv2sz=[]\n",
    "for t in tarray:\n",
    "    dft=df[df.time==t]\n",
    "    if (len(df)>1):\n",
    "#        timecorrect.append(t)\n",
    "        mean_cntr, var_cntr, std_cntr = bayesest(dft.Size,alpha=0.95)\n",
    "        meansz.append(mean_cntr[0])\n",
    "        errorsz.append(mean_cntr[1][1]-mean_cntr[0])\n",
    "        meancv2sz.append(var_cntr[0]/mean_cntr[0]**2)\n",
    "        errv=(var_cntr[1][1]-var_cntr[0])/mean_cntr[0]**2+2*(mean_cntr[1][1]-mean_cntr[0])*var_cntr[0]/mean_cntr[0]**3\n",
    "        errorcv2sz.append(errv)\n",
    "            #errorcv2gr.append((std_cntr[1][1]-std_cntr[0])/mean_cntr[0]+(mean_cntr[1][1]-mean_cntr[0])*std_cntr[0]/(mean_cntr[0])**2)\n",
    "plt.errorbar((np.array(tarray)-0.2),(np.array(meansz)+0.05),yerr=errorcv2sz,\n",
    "                               color='#008658',capsize=3,fmt='o',markersize='3',elinewidth=2)\n",
    "plt.fill_between(timearray3/18, np.array(mnszarray3)+np.array(errmnsz3), np.array(mnszarray3)-np.array(errmnsz3),alpha=1, edgecolor='#4db8ff', facecolor='#4db8ff',\n",
    "    linewidth=0)    #        plt.scatter(tarray,meansz,lw=3)\n",
    "    #plt.fill_between(tarray, np.array(meansz)+np.array(errorsz), np.array(meansz)-np.array(errorsz),alpha=1, edgecolor='#4db8ff', facecolor='#4db8ff',\n",
    "    #linewidth=0)\n",
    "plt.xlim(0,5)\n",
    "plt.ylim(0.9,1.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib agg\n",
    "if not os.path.exists('./figures1'):\n",
    "    os.makedirs('./figures1') #Figures path\n",
    "data1=pd.read_csv(\"./CRMdataAddersyn.csv\")\n",
    "n=1\n",
    "for l in range(70):\n",
    "    df=data1.iloc[l]\n",
    "    t=df['time']/18\n",
    "    del df['time']\n",
    "    plt.clf()\n",
    "    \n",
    "    fig, ax = plt.subplots(2,1, figsize=(5,5))\n",
    "    ax[0].plot(np.array(timearray1)/doubling_time,mnszarray1,lw=2)\n",
    "    ax[0].fill_between(np.array(timearray1)/doubling_time,np.array(mnszarray1)-np.array(errmnszarray1),np.array(mnszarray1)\n",
    "                   +np.array(errmnszarray1),alpha=1, edgecolor='#4db8ff', facecolor='#4db8ff',linewidth=0,label=\"SSA\")\n",
    "    ax[0].set_xlim(0,7)\n",
    "    ax[0].plot([t,t],[1,1.7],ls=\"--\",lw=1,c='k')\n",
    "\n",
    "    counts,values = np.histogram(df,bins=np.linspace(0.5,3,100))\n",
    "    ax[1].vlines(values, 0, counts/5000, color='#009447', lw=4)\n",
    "    mn=np.mean(df)\n",
    "    std=np.std(df)\n",
    "    #sumi=np.sum(np.array(pop)[:,4])\n",
    "    ax[1].plot([mn,mn],[0,0.9],c='k',lw=2)\n",
    "    ax[1].plot([mn-std,mn+std],[0.7,0.7],c='k',lw=2)\n",
    "    ax[1].text(mn-0.1,1.0,\"mean\",fontsize=12)\n",
    "    #ax[1].arrow(mn, 0.8, std, 0,width=0.002,color='k')\n",
    "    #ax[1].arrow(mn, 0.8, -std, 0,width=0.002,color='k')\n",
    "    \n",
    "    ax[1].set_xlim(0,3)\n",
    "    ax[1].set_ylim(0,1.2)\n",
    "    ax[0].set_xlabel(r'$t/\\tau$',fontsize=12)\n",
    "    ax[0].set_ylabel(\"$s$ (fl)\",fontsize=12)\n",
    "    ax[1].set_xlabel(\"$s$ (fl)\",fontsize=12)\n",
    "    ax[1].set_ylabel(r'$\\rho(s)$',fontsize=12)\n",
    "    ax[1].text(2.3,1.1,r'$t/\\tau=%.1f$'%t,fontsize=12)\n",
    "    plt.subplots_adjust(hspace=0.5,wspace=0.2)\n",
    "    for m in [0,1]:\n",
    "        ax[m].grid()\n",
    "        ax[m].tick_params(axis='x', labelsize=12)\n",
    "        ax[m].tick_params(axis='y', labelsize=12)\n",
    "        for axis in ['bottom','left']:\n",
    "            ax[m].spines[axis].set_linewidth(2)\n",
    "            ax[m].tick_params(axis='both', width=2,length=6)\n",
    "        for axis in ['top','right']:\n",
    "            ax[m].spines[axis].set_linewidth(0)\n",
    "            ax[m].tick_params(axis='both', width=0,length=6)\n",
    "    \n",
    "    plt.savefig('./figures1/'+str(n+10000)+'.jpg',bbox_inches='tight')\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV2sz = 0.01\n",
    "CV2div = 0.01\n",
    "CV2gr = 0.02\n",
    "\n",
    "div_steps=20\n",
    "v0 = mean_size*np.random.gamma(shape=1/CV2sz,scale=CV2sz,size=ncells)\n",
    "sim = Simulator(ncells=ncells, gr = gr, sb=mean_size, steps = div_steps, CV2div = CV2div, CV2gr = CV2gr,V0array=v0)\n",
    "sim.szdyn(tmax = tmax, sample_time= 0.1*doubling_time, nameCRM = \"./dataCRM6.csv\")\n",
    "#sim.szdynFSP(tmax = tmax, nameFSP = \"./dataFSP6.csv\",CV2sz=CV2sz) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./dataCRM6.csv\")\n",
    "taumax=60\n",
    "tauarr7=range(taumax)\n",
    "tarr=data.time.tolist()\n",
    "corarr7=[]\n",
    "for tau in tauarr7:\n",
    "    xx=[]\n",
    "    yy=[]\n",
    "    for i in range(30):\n",
    "        df=data[data.time==tarr[i]]\n",
    "        del df['time']\n",
    "        df2=data[data.time==tarr[i+tau]]\n",
    "        del df2['time']\n",
    "        print\n",
    "        #print(df.iloc[0].tolist())\n",
    "        A=df.iloc[0].tolist()\n",
    "        B=df2.iloc[0].tolist()\n",
    "        for m in range(len(A)):\n",
    "            xx.append(A[m])\n",
    "        for m in range(len(A)):\n",
    "            yy.append(B[m])\n",
    "        #xx.append()\n",
    "        #yy.append(df2.tolist())\n",
    "    #print(len(xx))\n",
    "    corarr7.append(np.corrcoef(xx,yy)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./dataCRM6.csv\")\n",
    "taumax=60\n",
    "tauarr7=range(taumax)\n",
    "tarr=data.time.tolist()\n",
    "corarrmat7=np.zeros([len(tarr)-taumax,len(tauarr7)])\n",
    "l=0\n",
    "m=0\n",
    "for l in range(len(tarr)-taumax):\n",
    "    for m in range(len(tauarr7)):\n",
    "        df=data[data.time==tarr[l]]\n",
    "        del df['time']\n",
    "        df2=data[data.time==tarr[l+m]]\n",
    "        del df2['time']\n",
    "        A=df.iloc[0].tolist()\n",
    "        B=df2.iloc[0].tolist()\n",
    "        corarrmat7[l][m]=np.corrcoef(A,B)[0][1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv(\"./dataCRM6.csv\")\n",
    "timearray7=data1.time.unique()\n",
    "\n",
    "mnszarray7=[]\n",
    "cvszarray7=[]\n",
    "errcv2sz7=[]\n",
    "errmnsz7=[]\n",
    "df=data1\n",
    "del df['time']\n",
    "for m in range(len(df)):\n",
    "    szs=df.loc[m, :].values.tolist()\n",
    "    mean_cntr, var_cntr, std_cntr = bayesest(szs,alpha=0.95)\n",
    "    mnszarray7.append(np.mean(szs))\n",
    "    errmnsz7.append(mean_cntr[1][1]-mean_cntr[0])\n",
    "    cvszarray7.append(np.var(szs)/np.mean(szs)**2)\n",
    "    errv=(var_cntr[1][1]-var_cntr[0])/mean_cntr[0]**2+2*(mean_cntr[1][1]-mean_cntr[0])*var_cntr[0]/mean_cntr[0]**3\n",
    "    errcv2sz7.append(errv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mticker\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(10,8))\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "\n",
    "\n",
    "##increased pad from 0.1 to 0.2 so that tick labels don't overlap\n",
    "xhax = divider.append_axes(\"top\", size=1, pad=0.2, sharex=ax)\n",
    "yhax = divider.append_axes(\"right\", size=1, pad=0.2, sharey=ax)\n",
    "\n",
    "##'normalizing' x and y values to be between 0 and 1:\n",
    "xn = (x-min(x))/(max(x)-min(x))\n",
    "yn = (y-min(y))/(max(y)-min(y))\n",
    "\n",
    "##producinc the plots\n",
    "\n",
    "#ax.scatter(xn, yn)\n",
    "xhax.plot(tauarr7,np.array(corarr7))\n",
    "yhax.plot(mnszarray7,range(len(mnszarray7)))\n",
    "#yhax.hist(yn,)\n",
    "\n",
    "##turning off duplicate ticks (if needed):\n",
    "plt.setp(xhax.get_xticklabels(), visible=False)\n",
    "plt.setp(yhax.get_yticklabels(), visible=False)\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlabel(\"lag\",fontsize=20)\n",
    "ax.set_ylabel(r\"$t/\\tau$\",fontsize=20)\n",
    "xhax.set_ylabel(r\"$\\gamma(t)$\",fontsize=20)\n",
    "yhax.set_xlabel(r\"$\\langle s \\rangle$\",fontsize=20)\n",
    "\n",
    "\n",
    "sns.heatmap(np.array(corarrmat7),ax=ax,cmap=\"terrain\",annot=False)\n",
    "\n",
    "xhax.grid()\n",
    "xhax.tick_params(axis='x', labelsize=12)\n",
    "xhax.tick_params(axis='y', labelsize=12)\n",
    "for axis in ['bottom','left']:\n",
    "    xhax.spines[axis].set_linewidth(2)\n",
    "    xhax.tick_params(axis='both', width=2,length=6)\n",
    "for axis in ['top','right']:\n",
    "    xhax.spines[axis].set_linewidth(0)\n",
    "    xhax.tick_params(axis='both', width=0,length=6)\n",
    "    \n",
    "yhax.grid()\n",
    "yhax.tick_params(axis='x', labelsize=12)\n",
    "yhax.tick_params(axis='y', labelsize=12)\n",
    "for axis in ['top','left']:\n",
    "    yhax.spines[axis].set_linewidth(2)\n",
    "    yhax.tick_params(axis='both', width=2,length=6)\n",
    "for axis in ['bottom','right']:\n",
    "    yhax.spines[axis].set_linewidth(0)\n",
    "    yhax.tick_params(axis='both', width=0,length=6)\n",
    "taqui=np.arange(0,70,step=10)\n",
    "ax.set_xticks(np.array(taqui))\n",
    "\n",
    "taqui=np.arange(1,1.8,step=0.2)\n",
    "yhax.set_xticks(np.array(taqui))\n",
    "\n",
    "taqui=np.arange(0,50,step=10)\n",
    "ax.set_yticks(np.array(taqui))\n",
    "ax.tick_params(axis='both', width=2,length=4)\n",
    "for axis in ['bottom','left']:\n",
    "    ax.spines[axis].set_linewidth(2)\n",
    "    \n",
    "yhax.xaxis.tick_top()\n",
    "yhax.xaxis.set_label_position('top') \n",
    "#ax.tick_params(labelbottom=False,labelleft=False,)\n",
    "#ax.setp(ax.get_xticklabels(), visible=False)\n",
    "#\n",
    "#ax.set_xticks(np.array(taqui))\n",
    "#taqui=np.arange(0,20,step=1)\n",
    "#ax.set_yticks(np.array(taqui))\n",
    "plt.savefig('./heatmap2.eps',bbox_inches='tight',dpi=600)\n",
    "plt.savefig('./heatmap2.svg',bbox_inches='tight',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CV2sz = 0.01\n",
    "CV2div = 0\n",
    "CV2gr = 0\n",
    "\n",
    "div_steps=20\n",
    "v0 = mean_size*np.random.gamma(shape=1/CV2sz,scale=CV2sz,size=ncells)\n",
    "sim = Simulator(ncells=ncells, gr = gr, sb=mean_size, steps = div_steps, CV2div = CV2div, CV2gr = CV2gr,V0array=v0)\n",
    "sim.szdyn(tmax = tmax, sample_time= 0.1*doubling_time, nameCRM = \"./dataCRM6.csv\")\n",
    "#sim.szdynFSP(tmax = tmax, nameFSP = \"./dataFSP6.csv\",CV2sz=CV2sz) \n",
    "\n",
    "\n",
    "data=pd.read_csv(\"./dataCRM6.csv\")\n",
    "taumax=60\n",
    "tauarr7=range(taumax)\n",
    "tarr=data.time.tolist()\n",
    "corarr7=[]\n",
    "for tau in tauarr7:\n",
    "    xx=[]\n",
    "    yy=[]\n",
    "    for i in range(30):\n",
    "        df=data[data.time==tarr[i]]\n",
    "        del df['time']\n",
    "        df2=data[data.time==tarr[i+tau]]\n",
    "        del df2['time']\n",
    "        print\n",
    "        #print(df.iloc[0].tolist())\n",
    "        A=df.iloc[0].tolist()\n",
    "        B=df2.iloc[0].tolist()\n",
    "        for m in range(len(A)):\n",
    "            xx.append(A[m])\n",
    "        for m in range(len(A)):\n",
    "            yy.append(B[m])\n",
    "        #xx.append()\n",
    "        #yy.append(df2.tolist())\n",
    "    #print(len(xx))\n",
    "    corarr7.append(np.corrcoef(xx,yy)[0][1])\n",
    "\n",
    "data=pd.read_csv(\"./dataCRM6.csv\")\n",
    "taumax=60\n",
    "tauarr7=range(taumax)\n",
    "tarr=data.time.tolist()\n",
    "corarrmat7=np.zeros([len(tarr)-taumax,len(tauarr7)])\n",
    "l=0\n",
    "m=0\n",
    "for l in range(len(tarr)-taumax):\n",
    "    for m in range(len(tauarr7)):\n",
    "        df=data[data.time==tarr[l]]\n",
    "        del df['time']\n",
    "        df2=data[data.time==tarr[l+m]]\n",
    "        del df2['time']\n",
    "        A=df.iloc[0].tolist()\n",
    "        B=df2.iloc[0].tolist()\n",
    "        corarrmat7[l][m]=np.corrcoef(A,B)[0][1]\n",
    "        \n",
    "\n",
    "data1=pd.read_csv(\"./dataCRM6.csv\")\n",
    "timearray7=data1.time.unique()\n",
    "\n",
    "mnszarray7=[]\n",
    "cvszarray7=[]\n",
    "errcv2sz7=[]\n",
    "errmnsz7=[]\n",
    "df=data1\n",
    "del df['time']\n",
    "for m in range(len(df)):\n",
    "    szs=df.loc[m, :].values.tolist()\n",
    "    mean_cntr, var_cntr, std_cntr = bayesest(szs,alpha=0.95)\n",
    "    mnszarray7.append(np.mean(szs))\n",
    "    errmnsz7.append(mean_cntr[1][1]-mean_cntr[0])\n",
    "    cvszarray7.append(np.var(szs)/np.mean(szs)**2)\n",
    "    errv=(var_cntr[1][1]-var_cntr[0])/mean_cntr[0]**2+2*(mean_cntr[1][1]-mean_cntr[0])*var_cntr[0]/mean_cntr[0]**3\n",
    "    errcv2sz7.append(errv)\n",
    "\n",
    "\n",
    "##setting up ticks and labels to simulate real data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mticker\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(10,8))\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "\n",
    "\n",
    "##increased pad from 0.1 to 0.2 so that tick labels don't overlap\n",
    "xhax = divider.append_axes(\"top\", size=1, pad=0.2, sharex=ax)\n",
    "yhax = divider.append_axes(\"right\", size=1, pad=0.2, sharey=ax)\n",
    "\n",
    "##'normalizing' x and y values to be between 0 and 1:\n",
    "xn = (x-min(x))/(max(x)-min(x))\n",
    "yn = (y-min(y))/(max(y)-min(y))\n",
    "\n",
    "##producinc the plots\n",
    "\n",
    "#ax.scatter(xn, yn)\n",
    "xhax.plot(tauarr7,np.array(corarr7))\n",
    "yhax.plot(mnszarray7,range(len(mnszarray7)))\n",
    "#yhax.hist(yn,)\n",
    "\n",
    "##turning off duplicate ticks (if needed):\n",
    "plt.setp(xhax.get_xticklabels(), visible=False)\n",
    "plt.setp(yhax.get_yticklabels(), visible=False)\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlabel(\"lag\",fontsize=20)\n",
    "ax.set_ylabel(r\"$t/\\tau$\",fontsize=20)\n",
    "xhax.set_ylabel(r\"$\\gamma(t)$\",fontsize=20)\n",
    "yhax.set_xlabel(r\"$\\langle s \\rangle$\",fontsize=20)\n",
    "\n",
    "\n",
    "sns.heatmap(np.array(corarrmat7),ax=ax,cmap=\"terrain\",annot=False)\n",
    "\n",
    "xhax.grid()\n",
    "xhax.tick_params(axis='x', labelsize=12)\n",
    "xhax.tick_params(axis='y', labelsize=12)\n",
    "for axis in ['bottom','left']:\n",
    "    xhax.spines[axis].set_linewidth(2)\n",
    "    xhax.tick_params(axis='both', width=2,length=6)\n",
    "for axis in ['top','right']:\n",
    "    xhax.spines[axis].set_linewidth(0)\n",
    "    xhax.tick_params(axis='both', width=0,length=6)\n",
    "    \n",
    "yhax.grid()\n",
    "yhax.tick_params(axis='x', labelsize=12)\n",
    "yhax.tick_params(axis='y', labelsize=12)\n",
    "for axis in ['top','left']:\n",
    "    yhax.spines[axis].set_linewidth(2)\n",
    "    yhax.tick_params(axis='both', width=2,length=6)\n",
    "for axis in ['bottom','right']:\n",
    "    yhax.spines[axis].set_linewidth(0)\n",
    "    yhax.tick_params(axis='both', width=0,length=6)\n",
    "taqui=np.arange(0,70,step=10)\n",
    "ax.set_xticks(np.array(taqui))\n",
    "\n",
    "taqui=np.arange(1,1.8,step=0.2)\n",
    "yhax.set_xticks(np.array(taqui))\n",
    "\n",
    "taqui=np.arange(0,50,step=10)\n",
    "ax.set_yticks(np.array(taqui))\n",
    "ax.tick_params(axis='both', width=2,length=4)\n",
    "for axis in ['bottom','left']:\n",
    "    ax.spines[axis].set_linewidth(2)\n",
    "    \n",
    "yhax.xaxis.tick_top()\n",
    "yhax.xaxis.set_label_position('top') \n",
    "#ax.tick_params(labelbottom=False,labelleft=False,)\n",
    "#ax.setp(ax.get_xticklabels(), visible=False)\n",
    "#\n",
    "#ax.set_xticks(np.array(taqui))\n",
    "#taqui=np.arange(0,20,step=1)\n",
    "#ax.set_yticks(np.array(taqui))\n",
    "plt.savefig('./heatmap1.eps',bbox_inches='tight',dpi=600)\n",
    "plt.savefig('./heatmap1.svg',bbox_inches='tight',dpi=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
